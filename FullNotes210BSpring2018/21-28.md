# 21讲座21

在最后一类中，我们证明了下列过程收敛定理。

定理21.1。假设对于每个n≥1，{Xn（t），t∈[0,1]}是一个随机过程，其实现是`∞[0,1]中的函数假设{Xt，t∈[0,1]}是另一个随机过程，其实现是C[0,1]中的函数假设以下两个条件成立：

*1.*    对于k≥1和t1，…，tk∈[0,1]，

（X n（t1），…，Xn（tk））→L（X（t1），…，X（tk））作为n·····（196）

这种假设称为有限维收敛。

*2.*    对于每一个δ＞0，都存在一个整数和一个有限网格0＝t0<t1<…·tk＝1＝tk＝1这样

为所有人。（197）

这种假设称为随机等连续性或渐近等连续性。

然后对于每一个有界连续函数h：`∞[0,1]→R（这里我们把`∞[0,1]看作是一致度量下的度量空间），我们得到

Eh（X n）→Eh（X）作为n·····（198）

这里有一些关于这个定理的评论。

√

\1.    如果Xn的采样路径有跳跃（例如Xn（t）=n（Fn（t）－t）），则（如前一类中所述）h（Xn）不必对每个有界连续函数h：`∞[0,1]→R都是可测的。在这种情况下，Eh（Xn）可能没有正确的定义。可以通过将E h（Xn）替换为其外部期望E*h（Xn）来解决这个问题

E*H（Xn）：＝INF{eB:B是可测量的，B超过H（Xn），EB存在}。

如果用E*h（Xn）代替Eh（Xn），则定理的结果是真的在我们的治疗中，我们将忽略这些可测量的问题。有关详细分析，请参见加藤[12]。

\2.    我们取（198）作为`∞[0,1]中随机过程序列{Xn}到X收敛性的定义。我们把它写成X n→L X作为n·····。与在欧氏空间上分布收敛的情况一样，以下是Xn→L X的等价定义：

(a)    每个有界Lipschitz函数h的E∗h（Xn）→Eh（X）：`∞[0,1]→R。

(b)    对于`∞[0,1]中的每个开集G，我们都有liminfn→∞P∗{Xn∈G}≥P{X∈G}。

(c)    对于`∞[0,1]中的每一个闭集F，我们有limsupn→∞P∗{Xn∈F}≤P{X∈F}。

过程收敛的一个重要结果是连续映射定理：假设Xn→L X和g：`∞[0,1]→Rk是连续的，则g（Xn）→lg（X）这是过程收敛定义的一个微不足道的结果。

\3.    有限维收敛通常是Lindeberg-Feller中心极限定理的结果四。随机等连续性隐含于

=0，每δ>0

进一步暗示

四肢支撑| Xn（s）–Xn（t）|=0.（199）

η≤0n→∞0≤s，t≤1：| s−t |≤

例如，看到（199）意味着（197），注意每一个> 0和三角形> 0，有0个这样的

![img](file:///C:/Users/ADMINI~1/AppData/Local/Temp/msohtmlclip1/01/clip_image002.gif)

这进一步意味着一个整数的存在，对于所有人来说，

![img](file:///C:/Users/ADMINI~1/AppData/Local/Temp/msohtmlclip1/01/clip_image004.gif)

设0=t0<t1<·····<tk=1为[0,1]中的均匀网格，间距η为

![img](file:///C:/Users/ADMINI~1/AppData/Local/Temp/msohtmlclip1/01/clip_image006.gif)

所以通过马尔可夫不等式，我们得到

为所有人

这证明了（197）。

在定理21.1中，区间[0,1]可以被R的任何其他紧子区间[a，b]所代替。事实上，它可以被任何抽象集T所代替。在这种情况下，我们将跳过下列定理的证明（证明可以在Kato[12，定理11]中找到）。

设`∞（T）表示T上所有有界函数的空间，将其视为具有度量（f1，f2）7→supt∈T | f1（T）－f2（T）|的度量空间。

定理21.2。对于每个n≥1，设Xn（t），t∈t是一个在`∞（t）中实现的随机过程。假设

*1.*    对于k≥1和t1，…，tk∈T，随机向量序列（Xn（t1），…，Xn（tk））在分布上收敛到一定的极限。

*2.*    t上存在一个半度量D，它（t，d）是完全有界的，并且

四肢支撑| Xn（s）–Xn（t）|=0。

η≤0n→∞0≤s，t≤1:d（s，t）≤

然后，存在一个随机过程x（t），t't，它的实现是T（关于度量D）上的连续函数，使得在每个有界连续函数H：‘0’（t）~r中，“n”（t）中的xn×l x，或等价地，E＊H（xn）-ε（x），作为n＝~（0）。

注意定理21.2不是以极限对象X开始的，而是用连续样本路径（相对于度量n满足Xn满足随机等度连续性）来判定过程x（t）、t（t）的存在性。注意，极限对象必然满足（Xn（t1），…，Xn（T k））在分布上收敛到（X（t1），…，X（tk））的性质，对于每k≥1和t1，…，tk∈T。

## 21.1个极大不等式与随机等度连续性

如我们所见，过程收敛的关键条件是随机等连续性。为了证明这一点，我们显然需要

E sup | Xn（s）–Xn（t）|。

0≤s，t≤1:d（s，t）≤

在大多数应用中，Xn将与经验过程相关，因此我们得到了经验过程的期望上确界。

让我们先用一个例子来说明总体思路。假设指数集T=[0,1]和Xn是统一的经验过程，即。，

![img](file:///C:/Users/ADMINI~1/AppData/Local/Temp/msohtmlclip1/01/clip_image008.gif)

式中，Pn是与观测值X1，…，Xn相对应的经验测量值，其i.i.d在[0,1]上是一致的（P也是[0,1]的分布）在这里我们将试图证明Xn满足随机等连续性为此，首先要注意

![img](file:///C:/Users/ADMINI~1/AppData/Local/Temp/msohtmlclip1/01/clip_image010.gif)

我们使用以下符号：

对于η∈[0,1]。

我们可以利用经验过程的期望上确界来控制

.

经验过程的期望上确界的一个主要界限（从第9课开始）是

)（200个）

哪里

![img](file:///C:/Users/ADMINI~1/AppData/Local/Temp/msohtmlclip1/01/clip_image012.gif)

其中H是H的包络，定义为H（x）：=suph∈H | H（x）|将其应用于H=Gη，我们得到

![img](file:///C:/Users/ADMINI~1/AppData/Local/Temp/msohtmlclip1/01/clip_image014.gif)

其中G是Gη的包络现在很容易看出G是等于1的常数函数。注意，PG2=1，而PG2≤η，对于每个g∈gη（换句话说，PG2远大于supg∈gηPG2）因为G∏1，上面的界限变成

![img](file:///C:/Users/ADMINI~1/AppData/Local/Temp/msohtmlclip1/01/clip_image016.gif)

我们现在证明上面的积分是由一个常数从上面限制的。至少有两种方式可以展示这一点对于第一种方法，证明类{I[0，s]-I[0，t]：0≤s，t≤1}具有有限的VC子图维数（最多3？？）并使用我们先前的包装数和VC子图维数之间的关系第二种方式，平凡的不平等

![img](file:///C:/Users/ADMINI~1/AppData/Local/Temp/msohtmlclip1/01/clip_image018.gif)

它适用于每一个s，t和每一对函数f1和f2，这意味着

.

这是因为我们可以在L2（Q）距离中覆盖函数I[0，s]-I[0，t]到2δ内，方法是覆盖单个函数I[0，t]到δ内，然后在覆盖中获取所有函数对。这给了

（201年）

其中c和c是正常数（后一个不等式是根据F是一个具有VC维数1的布尔函数类这一事实得出的）。

因此，我们已经证明

![img](file:///C:/Users/ADMINI~1/AppData/Local/Temp/msohtmlclip1/01/clip_image020.gif)

注意，上面的第二个不等式不能得到显著的改进，因为积分至少是1不幸的是，上面的约束不够强，无法屈服

（202）

为了改进我们的边界以推导出上述结果，我们需要使用优于（200）的边界。回想一下（从第9课开始），虽然（200）被称为一个主界，但它实际上遵循以下不等式：

（203）从这个界限，我们可以论证如下对于每个δ∈[0,1]，我们可以

![img](file:///C:/Users/ADMINI~1/AppData/Local/Temp/msohtmlclip1/01/clip_image022.gif)

通过（201），我们可以用常数代替第二个积分，用覆盖数F的积分代替第一个积分，得到

（204）最后一个期望上确界可以通过

!

其中我们使用了平凡不等式√a+b≤√a+√b。如前所述，supg∈GηPg2≤η

.

现在注意{g2:g∈gη}是一个VC维数最多为2的布尔类，因此

.

结合（204），我们得到

.

因此，

![img](file:///C:/Users/ADMINI~1/AppData/Local/Temp/msohtmlclip1/01/clip_image024.gif)

进一步

![img](file:///C:/Users/ADMINI~1/AppData/Local/Temp/msohtmlclip1/01/clip_image026.gif)

因为对于每一个δ>0都是这样，所以如果我们把右手边的极限取为δ→0，不等式也成立。现在很容易证明这个极限是零（这是因为从0到1的积分是有限的，所以从0到δ的积分应该作为δ→0由主导收敛定理变为零）从而证明了（202）与Xn（t），t∈[0,1]的随机等连续性相同。结合有限维收敛，证明了均匀经验过程在分布上收敛于布朗桥这是一致经验过程的Donsker定理。

我们必须做一点以上的工作，从（203）到（202）。存在其它极大不等式，使得人们更容易推断出（202）。下面的定理（摘自Kato[12，定理8]）就是这样一个结果。

定理21.3设H是H类的一个包络，其PH2<∞那么

（205）

每δ满足

.

在这里

r和Γ：=E最大H2（Xi）。

1≤i≤n

现在让我们证明定理21.3很容易得到（202）实际上，应用不平等（205）

√2≤η，PG2=1），得到H=Gη（包络H∏1）和δ=η（注意supg∈GηPg

![img](file:///C:/Users/ADMINI~1/AppData/Local/Temp/msohtmlclip1/01/clip_image028.gif)

这意味着

![img](file:///C:/Users/ADMINI~1/AppData/Local/Temp/msohtmlclip1/01/clip_image030.gif)

如前所述，变为0，即η≤0这给出了（202）的较短证明（尽管依赖于定理21.3的非平凡结果）。

# 22讲座22

在上一课中，我们证明了一致经验过程在`∞[0,1]中收敛于布朗桥的分布。其主要内容是证明均匀经验过程的随机等连续性条件。这个条件说明

四肢支撑| Xn（t）–Xn（s）|=0

η￥0 n→∞s，t∈[0,1]：| s−t |≤

其中Xn（t）是统一的经验过程我们上一次观察到这句话相当于

=0（206）

哪里

.

√

在这堂课中，我们将首先把这个论点推广到更一般的过程{n（Pnf-Pf）：f∈f}。具体地说，让F是一类函数

还有。

我们将在F上提供一个（206）成立的充分条件。为了控制（206）中的期望值，我们将使用下面的最大不等式（在前面的课中也有这样的表述）：

定理22.1。设H是H类的一个包络，其PH2<∞那么

（207）

每δ满足

.

在这里

r和Γ：=E最大H2（Xi）。

1≤i≤n

我们将定理22.1应用于H=Gη假设F是F的包络，那么很明显，2F是Gη的包络因此，我们在应用定理22.1时取H=2F我们得到

!

（208个）

哪里

![img](file:///C:/Users/ADMINI~1/AppData/Local/Temp/msohtmlclip1/01/clip_image032.gif)

这里，如定理22.1所示，δ是满足

.

因为supg∈GηPg2≤η，我们可以

![img](file:///C:/Users/ADMINI~1/AppData/Local/Temp/msohtmlclip1/01/clip_image034.gif)

所以δ/-0等于η/-0。因为Gη是FF的子集（FF是所有函数的类{f1f2:f1，f2∈F}），我们可以用F的填充数的平方来平凡地限定Gη的填充数，

![img](file:///C:/Users/ADMINI~1/AppData/Local/Temp/msohtmlclip1/01/clip_image036.gif)

对于正常数c，这给出

![img](file:///C:/Users/ADMINI~1/AppData/Local/Temp/msohtmlclip1/01/clip_image038.gif)

对于两个正常数c和c，将其插入（208），我们得到

.

因此，我们得到

.

下面的引理22.2则意味着上面右手边的limsup项等于零（只要J（cδ，F，F）<∞）

![img](file:///C:/Users/ADMINI~1/AppData/Local/Temp/msohtmlclip1/01/clip_image040.gif)

如果我们现在假设limδ＊0j（δ，F，F）=0，那么我们建立（206）。注意limδ≤0 J（δ，F，F）=0是

（209）

它有待于陈述和证明引理22.2。

引理22.2。假设Y1，…，Yn是E | Y1 |<∞的同分布随机变量（这里没有独立性假设）。那么

（210）

引理的证明22.2这是支配收敛定理的结果。我们写作

![img](file:///C:/Users/ADMINI~1/AppData/Local/Temp/msohtmlclip1/01/clip_image042.gif)

对于每个固定的x，很明显，上面的被积函数收敛为零，即n→∞此外，被积函数的界是（由并界和相同的分布假设）P{Y1 |>x}，P{Y1 |<∞积分到E | Y1 |<∞。因此，语句（210）遵循支配收敛定理。

## 22.1一致熵条件下的Donsker定理

因此，我们证明在条件（209）（称为均匀熵条件）下

√

随机过程Xn（f）：=n（Pnf-Pf）满足关于度量（f，g）→k7 f-gkL2（P）的随机等连续性条件。另一方面，我们也通过通常的多元中心极限定理在这里有有限维收敛，即。，

一

（Xn（f1），…，Xn（fk））→N（0，∑）

式中∑（i，j）=Cov（fi（X1），fj（X1））对于每k≥1和f1，…，fk∈F，我们可以应用上一类的过程收敛结果，得到Xn（F），F∈F在`∞（F）上的分布收敛该定理还保证了极限过程X（f），f∈f是一个高斯过程（即（X（f1），…，X（f k））对于每k≥1和f1，…，fk∈f）具有相对于度量（f，g）7→kfgkL2（P）的连续采样路径。这些结论在下面的定理中得到了重申。

定理22.3。假设均匀熵条件（209）。然后，存在一个具有连续样本路径的高斯过程X（f），F*过程F（关于由Xn（f）定义的度量{xn}：=πn（pN-kf＝gkL2（p）），使得随机ρ（f）的序列。

![img](file:///C:/Users/ADMINI~1/AppData/Local/Temp/msohtmlclip1/01/clip_image043.gif)

f-Pf），f∈f在分布上收敛到X-in`

定义22.4（Donsker函数类）。假设一类函数F相对于

√如果随机过程X n（f）：=n（Pnf−Pf），则概率测度P（也称为P-Donsker），f∈f在分布上收敛于高斯过程X（f），f∈f相对于度量（f，g）7→kf−gkL2（P）具有连续样本路径。

因此，定理（22.3）指出，如果F满足一致熵条件（209），那么对于每个概率测度P，F是PDonsker。

## 22.2 Donsker类的括号条件

用包围熵数代替（209）中的均匀熵，得到了P-Donsker的另一个充分条件。具体来说，假设

（211）

注意，这个条件取决于概率度量P（与（209）不同）。下面的定理证明了在上述条件下，F是P-Donsker。

定理22.5如果F满足概率测度P的括号条件（211），则F是PDonsker。

√

为了证明这一定理，足以证明过程Xn（f）=n（Pnf-Pf）在（211）下满足随机等连续性条件。为此，我们将从范德法特〔24，引理19.34〕中使用下列极大不等式。

定理22.6假设H是一类函数H的包络，并假设kHkL2（P）<∞。那么对于满足δ>0的每一个

,

以下不等式成立：

![img](file:///C:/Users/ADMINI~1/AppData/Local/Temp/msohtmlclip1/01/clip_image045.gif)

哪里

和

定理22.6与定理21.3中关于带括号的熵的类似。此外，定理22.6可以看出我们以前的基于包围的最大不等式的改进：

.

当δ很小时，定理22.6给出的界比上述界好得多。

我们现在用定理22.6证明定理22.5（关于定理22.6的证明，请参考Van der Vaart[24，引理19.34]）。

定理22.5的证明证明F是P-Donsker的关键是证明随机等连续性（有限维收敛遵循通常的中心极限定理）。对于随机等连续性，我们需要证明

![img](file:///C:/Users/ADMINI~1/AppData/Local/Temp/msohtmlclip1/01/clip_image047.gif)

哪里

.

为此，我们使用定理22.6，其中H：=Gη和H=2F（其中F是F的包络）来获得

![img](file:///C:/Users/ADMINI~1/AppData/Local/Temp/msohtmlclip1/01/clip_image049.gif)

具有

![img](file:///C:/Users/ADMINI~1/AppData/Local/Temp/msohtmlclip1/01/clip_image051.gif)

因为{f-g:f，g∈f}的括号数可以被f的括号数的平方所限制，我们得到

![img](file:///C:/Users/ADMINI~1/AppData/Local/Temp/msohtmlclip1/01/clip_image053.gif)

对于两个正常数c和c，我们得到

![img](file:///C:/Users/ADMINI~1/AppData/Local/Temp/msohtmlclip1/01/clip_image055.gif)

阿尔索

.

因此我们有

.

注意a0（δ）不依赖于n。上面的第二个项可以有界于

![img](file:///C:/Users/ADMINI~1/AppData/Local/Temp/msohtmlclip1/01/clip_image057.gif)

利用支配收敛定理，上述期望值收敛到零，即n········（注意，我们假设EF2（X1）·····）我们已经证明了

![img](file:///C:/Users/ADMINI~1/AppData/Local/Temp/msohtmlclip1/01/clip_image059.gif)

每δ>0在假设（211）下，上述右侧收敛为0，即δ→0。这证明了随机等连续性，从而证明了F是P-Donsker。

## 22.3样本中值收敛速度的应用

我们给出了一个例子来证明样本中值的收敛速度是研究过程收敛性的动机之一既然我们已经了解了什么是过程收敛，那么让我们回顾一下这个例子，并严格说明这个论点。设置如下我们有i.i.d数据X1，…，Xn是由N（θ0，1）分布产生的让

M（θ）：=E | X1−θ|

对于Tyr* R，估计Tyth-n定义为Mn（Th）上的最小极小值，同时也证明了Th 0唯一地最大化M（Th），Th·r。为了得到θˆn的极限分布，我们考虑了以下过程：

![img](file:///C:/Users/ADMINI~1/AppData/Local/Temp/msohtmlclip1/01/clip_image061.gif)

哪里

![img](file:///C:/Users/ADMINI~1/AppData/Local/Temp/msohtmlclip1/01/clip_image063.gif)

和

.

我们早先已经看到，A N（h）→la（h）：=h Z，其中Z∼N（0,1）和Bn（h）→B（h）：=M00（θ0）h2/2，对于每个固定的h∈R。第一个收敛是Lindeberg-Feller CLT的应用，第二个收敛是从Taylor展开到二阶的。这些收敛性声明实际上可以得到很大的加强。事实上，它认为

An→L A in`∞–[－Γ，Γ]对于每个固定的Γ>0（212）

和

Bn→B均匀地覆盖在每∏>0（213）的∏Γ，Γ]上

上述一致收敛意味着sup | h |≤Γ| B n（h）-B（h）|→0作为n→∞语句（213）通过通常的泰勒展开论证（左为练习）很容易证明。我们将在下面简述（212）的论点过程收敛性声明（212）需要两个要素：有限维收敛性和随机等连续性对于有限维收敛，我们需要证明

（An（h1），…，An（hk））→L（A（h1），…，A（hk））

对于每k≥1和h1，…，hk∈[-Γ，Γ]。这可以通过多元Lindeberg-Feller中心极限理论（左为练习）来证明。对于随机等连续性，我们需要证明

（214）

为此，请注意

E sup | An（h1）－An（h2）|＝E sup（n | Png－Pg |）h1，h2∈[Γ，Γ]：| h1－h2 |≤ηg∈gη

哪里

Gη：=nx→| 7X−θ0−n−1/2h1 |−x−θ0−n−1/2h2 |：h1，h2∈[——Γ，Γ]，| h1−h2 |≤ηo。

然后，可以使用经验过程的期望上确界（例如基于括号数字的界）中的一个界来证明语句（214）。这又是作为练习留下的。

可以将两个语句（212）和（213）添加到yield（验证这一点）：

对于每一个固定的Γ>0，在`∞[－Γ，Γ]中。

√因此，M∮n的极限过程为M∮（h）：=hZ+M00（θ0）h2/2，对于h∈R

![img](file:///C:/Users/ADMINI~1/AppData/Local/Temp/msohtmlclip1/01/clip_image064.gif)

如果我们能证明argminh∈R M∮n（h）在分布上收敛于argminh∈rm∮（h），则n（θˆn∏θ0）现在紧随其后这可以从一个一般的argmax连续映射定理中推导出来。

## 22.4 Argmax连续映射定理

定理22.7。设H为度量空间。设{Mn（h），h∈h}和{M（h），h∈h}为h指标的随机过程，假设下列条件成立：

*1.*    H的每个紧子集K的M→lm在`∞（K）中。

*2.*    M的每个实现在H上是连续的。

*3.*    H H使H（H）上的Mn（H）最大化。

*4.*    设H是H（H）上M（H）的唯一极大化子。

*5.*    紧密性：对于每一个，存在一个紧凑子集，使得

和

也就是说，对于每个有界连续函数f:H→R，我们有Ef（Hˆn）→Ef（Hˆ）作为n→∞。

备注22.1。通常情况下，定理22.7适用于该过程

和M？作为M？n的极限过程。在这种情况下，请注意，以及由此产生的紧密性条件

相当于θˆn-θ0=OP（rn-1）。因此，在应用定理22.7获得rn（θˆn-θ0）的渐近分布之前，需要证明一个初步的速率结果。

备注22.2我们可以将定理22.7应用于M n（θ）、θ∈Θ和M（θ）、θ∈Θ（而不是M∮n和M∮）这通常会导致θˆn的一致性结果。定理22.7的证明。足以证明

![img](file:///C:/Users/ADMINI~1/AppData/Local/Temp/msohtmlclip1/01/clip_image066.gif)

对于H的每个闭子集F，固定闭子集F⊆H，并在H中固定任意紧集K

![img](file:///C:/Users/ADMINI~1/AppData/Local/Temp/msohtmlclip1/01/clip_image068.gif)

它给予

![img](file:///C:/Users/ADMINI~1/AppData/Local/Temp/msohtmlclip1/01/clip_image070.gif)

现在请注意

![img](file:///C:/Users/ADMINI~1/AppData/Local/Temp/msohtmlclip1/01/clip_image072.gif)

是`∞（K）的闭子集。这是因为如果suph∈F∩K mk（h）－suph∈K mk（h）＞0，且mk→m在K中一致，则suph∈F∩K m（h）－suph∈K m（h）＞0。因此，从Mn在`∞（K）中收敛到M，我们得到

.

因此我们得到

.

我们现在宣称

.

原因是当右手握着时，我们有suph∈F∩K M（h）≥suph∈km（h）≥suph∈hm（h）M的样本路径的连续性和F的封闭性（这意味着F k是紧的）意味着SF H f k k（H）在F k的某个点上实现。M上的唯一最大假设将意味着f k k中实现m的最大值的点必须等于H，这意味着H.f f。

.

注意，这对于H的每个闭子集F和H的每个紧子集K都是正确的。现在固定>0并选择K作为紧性条件。这会给

![img](file:///C:/Users/ADMINI~1/AppData/Local/Temp/msohtmlclip1/01/clip_image074.gif)

让趋向于零来完成证明。

将此结果与上一节的过程收敛结果一起使用，以完成样本中值极限分布结果的证明。

# 23讲座23

本课程的主要目的是证明下列定理（范德法特[24，定理5.23]），这些定理证明了M-估计在某些一般条件下的渐近正态性为了稍微简化证明，我对定理做了一些简化（例如假设标准函数用R索引；Van der Vaart[24，定理5.23]中的完整定理适用于标准函数用Rk中的一个开集为固定k索引的情况）。

## 23.1抽象M估计结果

定理23.1假设{mθ，θ∈R}是一类由R.给定i.i.d观测值索引的函数

x1，…，具有分布p的Xn，我们将估计的πn定义为pNM上的任何极大值，超过π^ r。设TH 0是定义为Ph th*上的任何最大化的π-π的人口类似物。

*1.*    假设θ7→mθ（x）在θ0处可微，导数m˙θ0（x）几乎是确定的x（w.r.t P）。

*2.*    假设存在一个函数p（x），p p＜2＜ω（即λL2（p））

|mθ1（x）－mθ2（x）|≤Γ（x）|θ1－θ2 |（215）

对于所有θ1、θ2和x。

*3.*    假设θ7→M（θ）：=Pmθ在θ0处是两个连续可微的，M00（θ0）<0。

*4.*    θˆn对于θ0是一致的，即θˆn→Pθ0作为n→∞。

然后得出以下两个结论：

*1.*    θˆn到θ0的收敛速度为n−1/2，即|θˆn−θ0 |=OP（n−1/2）。

*2.*    以下情况成立：

如n·····（216）

在开始证明这个定理之前，让我们先看一下下面的注释。

\1.    该定理的条件在mθ（x）=––| x–θ|时成立，因此该定理可以看作是我们对上一类样本中值的极限分布结果的推广。

\2.    注意，假设标准函数θ7→mθ（x）仅在θ0处（几乎肯定是关于x）对θ可微一次但极限函数M（θ）=Pmθ假定为两次可微。如果我们坚持准则函数是二次可微的，那么这个定理将不再适用于mθ（x）=––| x–|θ|等函数。然而，M估计的渐近正态性的经典证明将泰勒展开到二阶，并且这些论据需要存在二阶导数（以及一些附加正则性）。

\3.    Th 0不被认为是M（Th），Th，r的唯一最大值，而不是这样，则假定Tyth-n对于Th 0是一致的，即它在概率上收敛到Th 0。这意味着θˆn将接近θ0，为了得到θˆn的渐近图，我们可以关注θ0的局部区域因此，这个定理是一个局部结果，所有的注意力都集中在θ0的局部区域上。

我们现在证明定理23.1。它将使用到目前为止我们在本课程中看到的一些想法和结果。

定理23.1的证明。第一个任务是证明收敛速度是n-1/2。为此，我们可以直接使用速率定理。设Mn（θ）：=Pnmθ和d（θ，θ0）=。为了确定利率，我们必须

E sup（Mn-M）（θ-θ0）

θ：|θ-θ0 |≤δ

然后把束缚等于δ2以上数量等于

E sup（Pn-P）（mθ-mθ0）≤E sup（Pn-P）（mθ-mθ0）|。

θ：|θ-θ0 |≤δθ：|θ-θ0 |≤δ

为了控制上述期望的上确界，我们使用括号边界（从第12课开始）：

（217）

这里的相关类H是{mθ–-mθ0:|θ–-θ0 |≤δ}，其包络（根据Lipschitz条件（215））可以被认为是H（x）：=Γ（x）δ。因此我们有

.

为了控制上面的括号数，我们使用第12课的这个结果：如果Θ⊆Rd包含在半径R的球中，并且如果{gθ：θ∈Θ}是满足| gθ1（x）–gθ2（x）|≤Υ（x）kθ1−θ2k的函数类，对于所有x和θ1，θ2∈Θ。如果Υ∈L2（P），则

每（218）

将这个结果与gθ：=mθ-mθ0和Υ=Γ的{gθ：|θ−θ0 |≤δ}类结合，我们得到了

.

因此我们得到

![img](file:///C:/Users/ADMINI~1/AppData/Local/Temp/msohtmlclip1/01/clip_image076.gif)

因为kΓkL2（P）是有限的因此，为了得到|θˆn－θ0 |的速率上限，我们可以解出δn−1/2=δ2，得到δ=n−1/2因此，我们证明了|θˆn-θ0 |=OP（n-1/2）。

现在我们将试图证明（216）为此，我们考虑

![img](file:///C:/Users/ADMINI~1/AppData/Local/Temp/msohtmlclip1/01/clip_image078.gif)

以h∈R为指标，可分解为M∮n（h）=An（h）+Bn（h），其中

![img](file:///C:/Users/ADMINI~1/AppData/Local/Temp/msohtmlclip1/01/clip_image080.gif)

还有通过对m 0（Th）的二阶泰勒展开，证明了m（Th）在其最大值为0的点（m＝0（t＝0）＝0）的情况下，它的最大值是两次连续可微的，这也意味着BN（H）收敛于

![img](file:///C:/Users/ADMINI~1/AppData/Local/Temp/msohtmlclip1/01/clip_image082.gif)

对于每个固定的h∈R，我们现在将证明，对于每个固定的K，a（h）在`∞[-K，K]中收敛于随机过程a（h）。为了证明这一点，第一步是建立有限维收敛，即（An（h1），…，An（hk））在分布上收敛于固定的K和h1，…，hk。为此，我们将使用林德伯格费勒CLT请注意

![img](file:///C:/Users/ADMINI~1/AppData/Local/Temp/msohtmlclip1/01/clip_image084.gif)

哪里

.

因为X1，…，Xn是i.i.d，我们有Cov（Cov（Yn1）。现在对于每个固定的h∈R，

![img](file:///C:/Users/ADMINI~1/AppData/Local/Temp/msohtmlclip1/01/clip_image086.gif)

现在通过对θ0处的准则函数mθ（x）的几乎确定的一阶导数假设，我们得到

)几乎可以肯定。

同样根据Lipschitz假设（215），我们有

.

因此通过控制收敛定理，我们得到

))如n·····。

同样，对于每个固定的h1和h2，我们都有nCov

因此

n个

十

Cov（Yni）→Cov（A（h1），…，A（hk））为n······

i=1

哪里

A（h）：=Zhpvar（˙mθ0（X1）），其中Z∼N（0,1）。

此外，请注意

.

因此

![img](file:///C:/Users/ADMINI~1/AppData/Local/Temp/msohtmlclip1/01/clip_image088.gif)

通过支配收敛定理（注意，我们假设

EΓ2（X1）<∞）。Lindeberg Feller CLT的假设都满足，因此我们可以得出结论

（A n（h1），…，An（hk））→L（A（h1），…，A（hk））作为n→∞

对于每个固定k≥1和h1，…，hk∈R。

为了将每个固定K的有限维收敛转化为`∞[-K，K]的过程级收敛，我们需要证明随机等连续性

E sup | An（h1）－An（h2）|=E sup | n（Png－Pg）| h1，h2∈[－K，K]：| h1－h2 |≤ηg∈gη

哪里

.

根据Lipschitz假设（215），很明显，函数x 7→ηn-1/2Γ（x）是Gη的包络。因此，边界（217）给出

![img](file:///C:/Users/ADMINI~1/AppData/Local/Temp/msohtmlclip1/01/clip_image090.gif)

很容易看出，对于一个足够小的正常数c，

.

因此，通过使用（218）来控制上面右边的括号数字，我们得到

.

因此我们得到

![img](file:///C:/Users/ADMINI~1/AppData/Local/Temp/msohtmlclip1/01/clip_image092.gif)

式中，CK是一个仅依赖于K的常数。上面的右手边显然是以η→0的形式归零这证明了{An（h），-K≤h≤K}的随机等连续性。结合前面建立的有限维收敛结果，我们可以推导出，对于每一个K≥0，在`∞[-K，K]中的An→L A。

还证明了Bn（h）到B（h）在每个固定h∈R上的早期收敛可以改进为在[-K，K]上的一致收敛。这是M在θ0处两次连续可微性的结果。

利用`∞.[-K，K]中的A n→L A和`.[-K，K]上的Bn→B一致，我们可以推导出M∮n=An+Bn→L M∮：=A+B in `∞.[-K，K]。因此，我们可以使用argmax连续映射定理（所有条件都满足）得出结论

.

这就完成了定理23.1的证明。

## 23.2 MLE申请

定理23.1适用于极大似然估计。设P={Pθ，θ∈Θ}表示一类概率测度，其中Θ是R的开子集，并假定X1，…，Xn是来自Pθ0的i.i.d观测。假设每个Pθ具有关于公共支配测度μ的密度Pθ。在这种情况下，

定理23.1适用于mθ（x）=logpθ（x）和P=Pθ0。如果定理23.1的假设成立，那么

√

因此，每个MLEθˆn都有n个收敛速度和

.

这个结果的优点是它只需要logpθ在θ0处可微一次就可以几乎确定x（函数˙mθ0（x）称为得分函数）。相比之下，MLE的渐近正态性的传统结果需要在Th 0上存在至少两个Logp Th的导数。渐近方差由

.

这里的分子是Fisher信息I（θ0）。在˙mθ0（x）的附加光滑性假设下，可以证明M00（θ0）=-I（θ0），因此渐近方差是熟悉的1/I（θ0）。涉及到额外光滑性的最清楚的假设是Le-Cam在二次均值下的可微性。

定义23.2（二次均值可微性（DQM））。我们认为{p ^，th} }在二次均值为0°的情况下是可微的，如果存在一个函数α^ 0×L2（p ^ 0），则

作为θ→θ0。

在DQM假设下，函数`˙θ0扮演得分函数的角色，Fisher信息将由I（θ0）=varPθ0（`˙θ0（X1））定义（更多细节将在下节课中给出）下一个结果断言了DQM下MLE的N（0,1/I（θ0））渐近分布和logpθ上的一个附加Lipschitz假设这是范德法特[24，定理5.39]。

定理23.3设Θ是θ0∈Θ的开集假设{Pθ，θ∈Θ}在θ0处满足DQM同时假设

|对数pθ1（x）－对数pθ2（x）|≤Γ（x）|θ1－θ2 |（219）

对于所有x和θ1，θ2在θ0的邻域中，Pθ0Γ2<∞如果I（θ0）>0且θˆn与θ0一致，则

.

证明定理23.3的一个关键因素是，DQM性质意味着另一个称为局部渐近正态性（LAN）的性质我们说{Pθ，θ∈Θ}在θ0满足LAN

（1）（220）

其中Sn在分布上收敛到Pθ0下的N（0，I（θ0））。下节课将展示，θ0处的DQM表示I=I（θ0）的LAN应该清楚的是（220）加上额外的Lipschitz假设（219）以及√θˆn的一致性意味着（23.3）首先要注意的是

![img](file:///C:/Users/ADMINI~1/AppData/Local/Temp/msohtmlclip1/01/clip_image093.gif)

（220）为M●n（h）如果我们定义了M（h）=h Z I-h2I/2，其中Z∼N（0,1）和I=I（θ0），则（220）意味着M（N）的有限维分布收敛于M（N）的有限维分布。在Lipschitz假设（219）下，这种有限维收敛可以用过程收敛来补充，从而在`∞.[-K，K]中对每一个固定的K≥0产生收敛然后可以使用argmax连续映射定理来产生（23.3）这将完成定理23.3的证明。因此，在DQM假设下建立（220）是证明定理23.3的关键。我们将在下节课中证明这一重要事实（DQM意味着LAN）。

# 24讲座24

本课程将讨论二次平均数（DQM）和局部渐近正态性（LAN）的可微性。我正在关注Pollard[19]中非常干净的处理方法，我建议您阅读这篇漂亮的文章。

## 24.1二次均值的可微性

基本设置如下我们有一类概率测度P：={Pθ，θ∈Θ}在一些空间上，这些空间被R的子集Θ索引（对于固定k≥1，扩展到Θ⊆Rk的情形是可能的，但是为了简单起见，我们将限制到k=1）。假设存在一个单西格玛有限测度μ，每个Pθ具有将由Pθ表示的密度以下是DQM的定义。

定义24.1（二次均值可微性（DQM））我们认为P在二次均值为0°时是可微的，如果存在一个函数α^ 0×L2（p ^ 0）

作为θ→θ0。

换句话说，如果P在θ0处满足DQM，那么我们得到了展开式：

![img](file:///C:/Users/ADMINI~1/AppData/Local/Temp/msohtmlclip1/01/clip_image095.gif)

其中rθ满足

.

LE-CAM表明，在DQM下，可以证明统计中的经典渐近结果（如极大似然估计的渐近正态性），而不要求密度Th 7×p（x）在0°上是两次或三次可微的。

以下引理表明，如果P在θ0处满足DQM，并且如果θ7→Pθ（x）在θ0处在通常意义上可微，则DQM给出的函数`˙θ0与logpθ（x）的通常导数一致。

引理24.2。设P在θ0∈Θ满足DQM，且函数`˙θ0。还假设θ7→pθ（x）在θ0处可微，导数p˙θ0（x）几乎确定x相对于测度μ那么

`˙θ0（x）pθ0（x）=a.s x（w.r.tμ）的p˙θ0（x）。

证明。假设{θn}是收敛到θ0的序列。DQM假设允许我们编写

)（221个）

对于所有x和n

（222）

如果有必要的话，我们假设

（223）

例如，这可以通过将{θn}替换为选择{nk}的子序列{θnk}来实现，以便

.

我们现在使用这个事实，它意味着几乎肯定（通过单调收敛），这进一步意味着fi→0几乎肯定为i····因此，假设（223）

0 a.s（w.r.tμ）作为n→∞。

因此，我们可以将（221）重写为

)a.s（w.r.tμ）为n→∞。（224）

现在让我们利用θ7→pθ（x）在θ0处可微，导数˙pθ0（x）几乎肯定是关于μ的，并写出

pθn（x）=pθ0（x）+（θn−θ0）p˙θ0（x）+o（|θn−θ0 |）a.s（w.r.tμ）as n→∞。（225）

观察（224）和（225）都保持几乎确定的x（关于μ）。

我们现在将处理两个不同的案件第一种情况是pθ0（x）>0在这种情况下，我们可以将（225）重写为（注意pθ0（x）不依赖于n，因此o（|θ−θ0 |/pθ0（x））=o（|θ−θ0 |）：

![img](file:///C:/Users/ADMINI~1/AppData/Local/Temp/msohtmlclip1/01/clip_image097.gif)

取两边的平方根，我们得到

.

√

通过x=0时x 7→x的泰勒展开到一阶，我们从上面推导出

.

通过与（224）的比较，我们推断

.

现在让我们考虑pθ0（x）=0的情况。在这种情况下，（224）和（225）分别变成

![img](file:///C:/Users/ADMINI~1/AppData/Local/Temp/msohtmlclip1/01/clip_image098.gif)

pθ（x）=o(

p n |θn−θ0 |）=•？pθn（x）=o（|θn−θ0 | 2）

pθn（x）=（θn-θ0）pθ0（x）+o（|θn-θ0）。

将上述两个方程等价，我们得到

o（|θn-θ0 | 2）=（θn-θ0）p˙θ0（x）+o（|θn-θ0 |）。

除以|θn－θ0 |，让n→∞，我们得到˙pθ0（x）=0，即在这种情况下，方程˙θ0（x）pθ0（x）=p˙θ0（x）也满足这就完成了证明上面的引理暗示

当pθ0（x）>0时。

上面的右边是经典的分数函数。因此，当DQM成立时，我们将函数`˙θ0称为得分函数。

经典分数函数的一个标准事实是，它对概率测度Pθ0的期望等于零。这方面的经典证明涉及交换微分阶w.r.tθ和积分：

.

以下引理表明，DQM假设直接暗示了这一事实。

引理24.3。假设P在θ0处满足DQM，且得分函数为`˙θ0那么

Z轴

`˙θ0（x）pθ0（x）dμ（x）=0。（226）

证明。设θn是收敛到θ0的序列通过DQM表示，我们可以写出（221），余项rθn满足（222）请注意

![img](file:///C:/Users/ADMINI~1/AppData/Local/Temp/msohtmlclip1/01/clip_image100.gif)

我们现在展开右边的正方形，上面将引出六个条件其中一项等于R pθ0=1，与左手边相消因此我们得到

![img](file:///C:/Users/ADMINI~1/AppData/Local/Temp/msohtmlclip1/01/clip_image102.gif)

上面右边的第一项在绝对值中显然是O（|θn−θ0 |）。第三项是O（（θn--θ0）2）最后一项（by（222））等于o（（θn-）θ0）2）。剩下的两项（第二项和第四项）可以通过Cauchy-Schwarz不等式控制为

![img](file:///C:/Users/ADMINI~1/AppData/Local/Temp/msohtmlclip1/01/clip_image104.gif)

到（222）和

![img](file:///C:/Users/ADMINI~1/AppData/Local/Temp/msohtmlclip1/01/clip_image106.gif)

再次通过（222）因此，很明显（227）中右边的前导项是第一项通过将方程（227）除以|θn−θ0 |，并让n→∞，我们推导出（226）。

我们现在将定义Fisher信息。假设P满足DQM且得分函数为˙θ0然后θ0处的Fisher信息由

.

引理24.3的证明中使用的论点引出了一个有趣而重要的事实，涉及`˙θ0和Fisher信息。因为R`˙θ0pθ0dμ=0，我们可以将其插入（227）中以获得（同样使用（227）中的最后两个项是o（|θn−θ0 | 2））：

.

在R（`˙θ0）2pθ0dμ=I（θ0）的情况下，我们得到

（228）

这一事实对于确定DQM意味着LAN是至关重要的关于（228）的有趣方面如下。语句（222）意味着krθnkL2（μ）=o（|θn--θ0 |）因此，如果我们使用上面左边的Cauchy-Schwarz不等式，我们得到左边是o（|θn−θ0 |）但是上面的等式意味着右手边是O（（θn-，θ0）2），这是一个更有力的结论，可以从

与Rθn.Pollard-Cauchy-Schwarz的L2（μ）范数相比，Rθn√pθ0dμ要小得多。因此

[19]将这种现象归因于函数√pθn2（μ）都有范数1（这在L中是清楚的

从以上（228）的证明中，并认为这是DQM魔力背后的主要原因。

## 24.2局部渐近正态性

DQM是关于密度pθ在θ0处的第一可微性的一个陈述。当然在DQM中没有提到二阶可微性。然而，值得注意的是，DQM假设意味着对数似然函数在θ0附近有一个二阶泰勒展开式，其尺度为n-1/2。这种局部泰勒展开称为局部渐近正态性（LAN），并在下面的结果中得到了证明。

定理24.4假设P在θ0处满足DQM，且得分函数为˙θ0，Fisher信息为I（θ0）。那么对于每个固定的h∈R，我们有

如n·····。

同样地，上述定理的结论可以写成

（1）作为n→∞。（229）

我们说P在θ0处满足LAN性质，如果对每个h∈R都满足，为什么这称为局部渐近正态性？要看到这个，首先要注意，在CLT，我们有

.

因此，作为（229）的结果，我们得到每h∈R，

)在X1，…，Xn∼i.i.d Pθ0下。

现在考虑一个第二估计问题，其中有一个观测Y，其密度属于{Qh，h∈R}如果Qh具有密度qsh，该密度qsh是具有平均h和方差1/I（θ0）的正态分布的密度很容易看出

)在Y∼N（0,1/I（θ0））下。

因此（229）有效地说{Pθ，θ∈Θ}（只要P满足DQM，它可以是任意的）的似然比类似于正常实验{Qh，h∈R}的似然比，其中Qh=N（h，1）。因此，在n-1/2尺度上，在θ0附近渐近地，原始统计问题P变成了一个正态平均估计问题。这就是为什么（229）被称为局部渐近正态性。

我们现在证明定理24.4。

定理24.4的证明。这个证明中的所有期望和概率都与概率测度Pθ0有关。写

哪里

我们会利用这个事实

)林在哪里

y→0

或等价地，β（y）=o（y2）作为y→0这给了

.

使用DQM表示，我们可以编写

![img](file:///C:/Users/ADMINI~1/AppData/Local/Temp/msohtmlclip1/01/clip_image108.gif)

哪里

.

因此我们得到

.

现在通过DQM观察，我们知道关于随机变量Rni的以下内容：

.

这给出了L1中的（1）和0（Pθ0），这进一步意味着

0个。另外，根据柯西-施瓦兹不等式，我们有

.

因此我们有

.

我们稍后会证明

（1）（230）

所以我们有

.

上面右手边的第三项在概率上明显收敛到−h2I（θ0）/4（根据强大数定律），因此为了完成定理24.4的证明，我们只需要证明

（231）

为此，写下

不，不

2XRni=2XEθ0Rni+2X（Rni-ERni）。

i=1 i=1 i=1

因为

,

我们得到

（1）如n·····（232）

请注意

![img](file:///C:/Users/ADMINI~1/AppData/Local/Temp/msohtmlclip1/01/clip_image110.gif)

我们现在用事实（228）来说明

![img](file:///C:/Users/ADMINI~1/AppData/Local/Temp/msohtmlclip1/01/clip_image112.gif)

以便

.

结合（232），我们得到（231）。为了完成定理24.4的证明，我们只需要验证（230）。这主要是β（y）=o（y2）作为y→0的结果事实证明，为了证明（230），这足以证明

（1）和max | Rni |=oPθ0（1）。（233）

1≤i≤n

实际上，如果这些语句成立，那么（作为β（y）=o（y2）），我们可以写（严格化这个）：

.

我们现在将通过证明（233）中的断言来完成证明对于（233）中的第一个断言，请编写

（对于大于0的固定值），

![img](file:///C:/Users/ADMINI~1/AppData/Local/Temp/msohtmlclip1/01/clip_image114.gif)

利用控制收敛定理，以n·····························。

对于（233）中的第二个断言，请编写

.

这就完成了定理24.4的证明。

# 25讲座25

这个类中的下一个（也是最后一个）主题是关于极大极小下界在这堂课中，我们将主要推动极小极大下界的研究。我们从研究这些问题的基本决策理论出发。

## 25.1决策理论框架

在一般抽象决策理论框架下，可以研究极小极大。这里描述了这个框架。这本书的经典参考文献是《弗格森》[8，第1章和第2章]。

我们有一个未知的参数θ。θ可以是实数、向量、函数或矩阵等，我们假设θ取已知集合Θ中的值，我们称之为参数空间。

数据一般用X表示。X也可以是实数、向量、函数或矩阵等。我们假设X取集合X中的值，称为样本空间。

X与θ之间的联系是X的分布依赖于通过已知概率测度Pθ得到的θ。所有概率测度的类{Pθ，θ∈Θ}将用P来表示。我们假设每个Pθ对于一个单西格玛有限测度μ都有一个密度Pθ。

接下来，我们有一个行动空间A，它对应于统计学家在问题中需要采取的行动（例如，在估计问题中，A将等于或大于Θ，在用空假设和替代假设检验问题时，A将对应于两个假设等。具体例子如下）。

损失函数L是定义在Θ×a上的非负函数，即对于每个参数θ∈Θ和作用a∈a，存在一个非负损失L（θ，a）。

非随机决策规则d是从X到A的函数，换句话说，d将一个动作关联到每个X∈X，决策规则d在特定参数值θ处的风险由

R（θ，d）：=EθL（θ，d（X））

上面的期望值是关于X∼Pθ的。

统计学家在决策问题中的目标是选择风险R（θ，d）较小的决策规则d然而，由于风险R（θ，d）依赖于未知的θ，所以“小风险”的说法需要进一步限定。换句话说，决策规则d的风险取决于未知参数值（或自然状态）是什么。所以当我们说小风险的时候，我们需要指定是指θ以上的一致小风险，还是指小平均风险，还是指小最坏情况风险。我们将在看到一些决策理论问题的例子后不久再讨论这个问题。

例25.1考虑在平方误差损失下由观测Y∼Nn（θ，In）估计向量θ∈Rn的问题假设已知θ是k-稀疏的，即θ中的非零项的数目最多为k。这可以放在上面概述的决策理论框架中，将Θ取为Rn中所有k-稀疏向量的集合，X=Rn，A=Θ或A=Rn（取决于我们是否希望估计量是k-稀疏的）和L（θ，A）=kθ-ak2。Pθ也是Nn（θ，In）分布决策规则是θ的简单估计，估计量θˆ的风险由

.

例25.2。考虑与上一个问题相同的设置，但现在假设我们要估计θ的L1范数（而不是整个向量θ）：kθk1：=|θ1 |+··+|θn |。然后，Θ、X和Pθ与上例中相同，但A=R，损失函数为L（θ，A）=（kθk1−A）2。

例25.3。考虑由独立观测值Y1，…，Yn和Yi∼N（f（i/N），1）估计Lipschitz函数f:[0,1]→R的问题，对于i=1，…，N，在这个问题中，我们可以把Θ取为从[0,1]到R的所有Lipschitz函数的类，对于f∈Θ，概率测度Pf是均值为（f（1/N），…，的多元正态分布，。。。，f（n/n））和协方差矩阵作用空间可以取为[0,1]上所有实值函数的空间，损失函数可以是：

或者。

例25.4。考虑从n个独立观测值X1，…，Xn（θ，1）中对H0:θ=0和H1:θ=1进行检验的问题因为我们正在测试θ=0和θ=1，所以我们认为只有这两个值是可能的，所以我们取Θ={0,1}。然后操作空间也是A={0,1}。自然损耗函数是L（θ，A）=I{θ6=A}给定一个决策规则d（test），其风险由

R（θ，d）=Pθ{θ6=d（X）}。

注意，如果θ=0，那么风险由R（0，d）=P0{d（X）=1}给出，这是通常的I型错误当θ=1时，风险由R（1，d）=P1{d（X）=0}给出，这是第二类错误。

例25.5。考虑基于n（θ，1）分布的n i.d观测X1，…，Xn检验H0:θ∈Θ0对H1:θ∈Θ1的假设的问题。在这种情况下，A={0,1}和

L（θ，a）=I{θ∈0，a=1}+I{θ∈1，a=0}。

决策规则（检验）d的风险由R（θ，d）=Pθ{d（X）=1}（如果θ∈0）和R（θ，d）=Pθ{d（X）=0}（如果θ∈1）给出。这些错误可分别被视为I类和II类错误注意，这取决于θ（即，对于每个θ∈Θ0有一个i型误差族，对于每个θ∈Θ1有一个II型误差族）。

## 25.2如何评价决策规则

如前所述，决策规则d的风险R（θ，d）取决于θ事实证明，通常不可能找到一个单一的决定规则d∗，以便

R（θ，d∗）≤R（θ，d）对于每个θ∈Θ和决策规则d。（234）

例如，在具有Θ=A⊆Rk和L（θ，A）=kθ−ak2的估计问题中。考虑固定θ0∈Θ的估计量d0（X）=θ0该估计量在θ=θ0（即R（θ0，d0）=0）时明显具有等于0的风险因此，如果存在满足（234）的判定规则D，则R（Th 0，D））r（Th 0，D0）＝0。因为θ0∈Θ在这里是任意的，这意味着

R（θ，d∗）=Eθkθ∗d∗（X）k2=0

对于每个θ∈Θ这意味着对于每一个θ∈Θ，在Pθ下d∗（X）=θ几乎是确定的对于一般类{Pθ，θ∈θ}，这显然是不可能的。

因此，我们不能指望有一个强有力的最佳决策规则d*（234）。获得最优性的放松概念有三种常见方法：

\1.    第一种方法是限制所有决策规则的一个子类例如，在参数估计问题中，通常将注意力限制在无偏或等变估计上在参数检验问题中，很自然地限制了对水平α检验或无偏水平α检验的关注。这种方法是在STAT 210A中采用的，我们不会在这里继续。

\2.    贝叶斯方法

\3.    极大极小法

我们将在这里详细研究Bayes和Minimax方法。

## 25.3贝叶斯方法

在这里，我们在Θ上确定了一个概率测度w，并通过它们的平均风险来评估决策规则（其中平均值是相对于w进行的）。换句话说，我们根据决策规则的平均风险来评估决策规则d：

Z轴

R（θ，d）dw（θ）（235）

关于概率测度w，概率测度w也被称为适当先验或简单先验。最小可实现的平均风险称为相对于w的Bayes风险，并用Z表示

RBayes（w）：=inf R（θ，d）w（dθ）。

dΘ

最小化（235）的估计量d被称为关于w的Bayes估计量。

这种评估决策规则的方法的明显问题是它依赖于先验w，在许多情况下，不清楚先验的合理选择是什么。例如，在例25.3的Lipschitz回归问题中，需要在[0,1]上的所有Lipschitz函数的类上选择一个先验，但不清楚如何做到这一点。

尽管存在上述问题，但Bayes方法的重要优点在于，找到Bayes规则（最小化（235）的规则）在原则上是可处理的。实际上，我们可以把（235）写成

Z Z Z Z Z Z Z Z

R（θ，d）dw（θ）=EθL（θ，d（X））dw（θ）=L（θ，d（X））d pθ（X）dw（θ）=L（θ，d（X））pθ（X）dμ（X）dw（θ）。

ΘXΘX

我们现在交换上面的积分顺序（这是允许的，因为损失函数是非负的）来得到

.

从简单的不等式

Z Z轴

L（θ，d（x））pθ（x）dw（θ）≥inf L（θ，a）pθ（x）dw（θ）

Θa∈aΘ

对于每个x∈x，应该清楚的是，最小化（235）的规则是由

.

密度

![img](file:///C:/Users/ADMINI~1/AppData/Local/Temp/msohtmlclip1/01/clip_image116.gif)

简单地说，在X |θ∼pθ和θ∼w模型中，给定X=X的θ的后验密度。因此，我们得到了众所周知的事实，即Bayes规则最小化了损失函数的后验期望。例如，在平方误差损失L（θ，a）=kθ-ak2的情况下，贝叶斯规则只是后验分布的期望。

上述计算也给出了关于w的Bayes风险的精确表达式：

亚拜（236）

## 25.4极大极小法

在minimax方法中，我们根据决策规则在θ∈Θ上的最坏情况（上确界）风险来评估决策规则。换言之，我们的目标是选择supθ∈R（θ，d）较小的决策规则d。这种方法的优点是不需要选择特定的先验分布。缺点是它只关注最坏的情况，可能被认为过于悲观。然而，这是目前应用最广泛的最优性准则。

最小最大风险定义为

RMinimax:=inf supEθL（θ，d（X））

dθ∈Θ

其中，下确界接管了所有决策规则d。如果

.

发现极大极小估计在许多问题中是很困难的，所以通常是近似极小的。有两种常用的近似极小值的概念。它们是根据“样本大小”或“维度”参数n定义的，该参数存在于大多数决策问题中。具体地说，我们假设决策问题的所有成分（即Θ，A，L（θ，A）和Pθ）可能都依赖于样本大小或维度参数n，并且我们只对n的大值感兴趣。在这种情况下，我们有以下两个定义：

\1.    Sharp Asymptotically Minimaxity：我们认为决策规则D是尖锐渐近极大极小。

![img](file:///C:/Users/ADMINI~1/AppData/Local/Temp/msohtmlclip1/01/clip_image118.gif)

如n·····这相当于

supR（θ，d∗）=RMinimax（1+o（1））作为n→∞。

θ∈Θ

\2.    速率最小化：我们认为决策规则D是速率极大极小

![img](file:///C:/Users/ADMINI~1/AppData/Local/Temp/msohtmlclip1/01/clip_image120.gif)

对于不依赖于n的常数C，这相当于

supR（θ，d∗）=O（RMinimax）作为n→∞θ∈Θ

现在考虑以下情况。假设我们构造了一个决策规则d*（比如用M-估计方法），并且我们很好地理解了它的性能，因为我们在它的最高风险上有一个上界un，也就是说，我们知道

supR（θ，d∗）≤un。

θ∈Θ

那么我们如何证明d*是minimax（在上述意义中的一个：minimax，sharp不对称minimax或rate minimax）显然，为了做到这一点，我们需要从下面绑定RMinimax实际上，如果我们证明了极小极大下界：

RMinimax≥n（237）

然后我们可以断言

\1.    最小n，如果n＝unn。

\2.    如果UN/N n＝1为n～ω，则为渐近渐近极大极小。

\3.    如果un/`n=O（1）为n～ω，则速率极小。

当然，做到这一点的关键是能够证明极小极大下界（即形式（237）的界），我们现在将研究这个下界。

## 25.5极大极小下界

基本上只有一种方法可以证明极大极小风险的下界。这涉及到用Bayes风险从下面限制minimax风险。的确

Θ上每个概率测度w的RMinimax≥RBayes（w）。（238）

如前所述，Bayes风险RBayes（w）是一个更容易处理的对象（与RMinimax相比），它有精确的表达式（236）。

不等式（238）可以重写为

贝耶斯

其中对所有概率测度w取上确界。另一方面，很容易看出极小极大风险满足：

.

因此我们有

贝耶斯。

现在假设

,

然后我们将得到RMinimax=supw RBayes（w），这意味着从下面限制最小最大风险的唯一方法是通过Bayes风险来确定适当的先验w。显然，内界和上界不能总是互换的；例如，

RMinimax=inf supEθL（θ，d（X））6=supinf EθL（θ，d（X））=0。

dθ∈Θθ∈Θd

但是，在某些情况下，它们可以互换。保证交换的定理称为极大极小定理。文献中存在这样的一个极小极大定理，其中一个例子是如下（已知的某个时间点）：

定理25.6设K是向量空间X的凸子集，L是Hausdorff拓扑向量空间Y的紧凸子集。设f:K×L→R是这样一个函数

*1.*    x 7→f（x，y）对于每个固定的y∈L是凸的。

*2.*    y 7→f（x，y）是凹的，对于每个固定的x∈K是连续的。

那么

inf sup f（x，y）=sup inf（x，y）。

x∈K y∈ly∈lx∈K

这个定理可以用来验证（25.5）。为此，我们可以取K为所有决策规则d的类，L为所有概率测度w的集合我们需要

Z轴

（d，w）7→EθL（θ，d（X））dw（θ）

对于每个固定的W，D在D中是凸的，在W中凹的W是正确的，但是为了保证D中的凸性，我们需要切换到随机决策规则，并将风险的概念推广到随机化的决策规则。为了验证紧性假设，需要在所有概率测度的空间上放置一个拓扑这些可以在相当普遍的情况下完成，但细节是相当复杂的您可以查看Le Cam and Yang[15]或Le Cam[14]了解详细信息。

总结这一节，不等式（238）总是正确的通常，RMinimax=supw RBayes（w）so（238）是获得极大极小下界的唯一方法因为Bayes风险的确切表达式（236），我们有

RMinimax≥RBayes（239）

我们将在续集中看到许多（239）的例子。一个简单的例子是下面我们可以使用（239）来证明精确的最小值。

例25.7（多元正态模型）考虑损失下由X∼Nn（θ，In）估计θ∈Rn的问题

.

在这种情况下，参数空间是Θ=Rn。估计量d（X）=X的风险等于1。结果表明，这是最小最大风险为此，设w为Rn上的正态分布，平均向量μ，协方差矩阵τ2In然后可以显式地计算Bayes风险RBayes（w）要了解这一点，请注意后验分布由

![img](file:///C:/Users/ADMINI~1/AppData/Local/Temp/msohtmlclip1/01/clip_image122.gif)

以便

亚拜。

这给了

每τ>0。

设τ····，得到RMinimax≥1。因为X在Rn上的最高风险不超过1，这证明了X是极大极小的。

# 26讲座26

在上节课中，我们看到了重要的极大极小下界：

RMinimax≥RBayes（w），对于Θ上的每个概率测度w。

在本课中，我们将讨论两个非平凡的例子，其中的上界可以用来建立自然估计的尖锐渐近最大值。第一个例子涉及稀疏正态均值估计第二个例子涉及在幂（L2范数）约束下的正态平均值的估计（这个结果被称为有限维Pinsker定理）。

## 26.1稀疏正态均值估计

考虑在平方误差损失下由观测Y∼Nn（θ，In）估计k-稀疏向量θ∈Rn的问题。该估计问题可以放在决策理论框架中，其中Θ是Rn中所有k-稀疏向量的集合，A=Rn和L（θ，A）=kθ-ak2Pθ也是概率测度Nn（θ，In）在本节中，我们假设稀疏水平k满足k=o（n）（即k/n→0作为n·····）。

从我们先前的结果，我们已经看到套索（这是相同的软阈值）估计器

![img](file:///C:/Users/ADMINI~1/AppData/Local/Temp/msohtmlclip1/01/clip_image123.gif)

具有调谐参数λ=p2log（n/k）满足

supEθL（θ，θˆλ）≤（2k对数（n/k））（1+o（1））为n→∞。

θ∈Θ

我们现在证明这个估计量是尖锐的渐近极大极小

RMinimax≥（2k对数（n/k））（1+o（1））为n→∞。（240）

以下论点摘自约翰斯顿[11，第8.6节]。

我们首先研究k=1（然后讨论一般的k=o（n））。对于k=1，参数Θ特别简单，由Rn中的1-稀疏向量组成这里自然先验是有限参数集{τe1，…，τen}上的一致先验，其中ei是通常的标准单位向量，τ≥0将被适当地选择（取决于n）我们先用w表示这个。

设后验分布用（p1n（Y），p2n（Y），…，pnn（Y））表示（即pin（Y）是与τe i相关的后验概率）。很容易看出

![img](file:///C:/Users/ADMINI~1/AppData/Local/Temp/msohtmlclip1/01/clip_image125.gif)

因此

对于i=1，…，n。

因此，后验均值（即Bayes估计量）由（τp1n（Y），…，τpnn（Y））给出。因此，在此之前的Bayes风险

亚拜。

通过用i=i对应的项替换上面的内和，我们得到了下界

亚拜

通过对称，上面的每一项都取相同的值，因此我们得到

亚拜。

为了计算上述期望值（注意，τ不是常数，但它随n变化），我们通过取Y1=τ+z1和Yi=zi作为i≥2，切换到标准高斯随机变量z1，…，zn然后我们需要计算：

.

我们将证明这一点

,

数量S收敛到1这就意味着

RMinimax≥RBayes

这将证明k=1所需的下限（240）。

√

为了便于记法，让我们表示λn=2logn，这样exp（。为了证明τn：=λn−logλn的S=1+o（1），我们只需要证明随机变量序列

![img](file:///C:/Users/ADMINI~1/AppData/Local/Temp/msohtmlclip1/01/clip_image127.gif)

概率收敛到0注意，a正是τe1的后验概率（我们在真值为τe1的情况下工作）因此，概率收敛到零意味着τe1的后验概率（当真值为τe1时）变为零，这直观地意味着将错过尖峰。

为了证明An→P 0，重写

![img](file:///C:/Users/ADMINI~1/AppData/Local/Temp/msohtmlclip1/01/clip_image129.gif)

哪里

Vn=（n−1）e负极τ2/2e负极τz1和。

很容易看出，Vn在概率上收敛到＋∞要看到这个，写下

![img](file:///C:/Users/ADMINI~1/AppData/Local/Temp/msohtmlclip1/01/clip_image131.gif)

√

因为λ=2对数，

![img](file:///C:/Users/ADMINI~1/AppData/Local/Temp/msohtmlclip1/01/clip_image133.gif)

现在

![img](file:///C:/Users/ADMINI~1/AppData/Local/Temp/msohtmlclip1/01/clip_image135.gif)

因为λn-τn················（几乎肯定）。

因此，为了证明An在概率上变为0，我们只需要证明Wn-1在概率上变为1为简单起见，重新编制索引并调用n-1作为n。

.

这只是i.i.d平均值，是一个随机变量但是τn依赖于n，所以我们不能应用通常的弱大数定律但是我们可以使用下面的弱定律。

定理26.1。对于每个n，设Xnk，1≤k≤n为独立随机变量设bn>0，bn····。假设n→∞

*1.*   ，和

*2.*   .

设Sn：=Xn1+···+Xnn并置。那么

概率为n·····。

√

我们应用上述定理，Xnk：=eτnzk，bn=eτnλn（回忆一下λn：=2logn）。定理26.1中的第一个条件可以检查如下。注意{Xnk |≤bn}={zk≤λn}，这样

.

为了验证定理26.1中的第二个条件，我们需要计算r=2：

![img](file:///C:/Users/ADMINI~1/AppData/Local/Temp/msohtmlclip1/01/clip_image137.gif)

因此

EX∮nkr=er2τn2/2Φ（λn-rτn）。（241）

因此

.

观察到λn最终将小于2τn，从而使λn-2τn为负因此

.

因此

![img](file:///C:/Users/ADMINI~1/AppData/Local/Temp/msohtmlclip1/01/clip_image139.gif)

如n·····。

定理26.1的两个条件已经被证明，我们现在可以应用它了我们需要计算一个，我们可以简单地使用（241），r=1这会给

)（242个）

因此定理26.1给出

![img](file:///C:/Users/ADMINI~1/AppData/Local/Temp/msohtmlclip1/01/clip_image141.gif)

这和

.

因此

.

从（242）开始，我们有

.

因为λn-τn········和λn+τn·········

Wn=1+oP（1）

这就是我们想要证明的。这证明了k=1时的（240）。

为了证明（240）对于一般k=o（n），其思想是使用独立块先验将索引{1，…，n}分成大小为m=mn=bn/knc的kn块在每个块上，在k=1的情况下，使用单个峰值总的来说，先验知识将使这些kn块独立。由于独立性，Bayes风险加起来，得到了2k对数（n/k）（1+o（1））的整体下界。我们需要假设k/n→0，因为在每个块中，我们需要观测数mn去无穷大。这就完成了（240）的证明。

## 26.2功率约束下的正态平均估计（有限维Pinsker定理）

考虑由损失函数中的Y∼Nn（θ，In）估计向量θ∈Rn的问题

![img](file:///C:/Users/ADMINI~1/AppData/Local/Temp/msohtmlclip1/01/clip_image143.gif)

在以下约束下：

对于固定的c>0。（243）

设Θ表示满足上述约束（在信号处理和信息论中，该约束常被称为功率约束）的所有θ∈Rn的类设A=Rn，通常Pθ是Nn（θ，In）分布。估计量θˆ的风险由下式给出

.

幂约束（243）下θ的最佳候选估计是什么？最自然的估计量是Y在Θ上的投影。这是一个M-估计，可以用我们以前的技术来分析。实际上，在本例中，投影具有显式形式

如果

如果是

注意，这是一个非线性估计量结果表明，在这个问题中，对于适当的α>0，αY形式的简单线性估计有很好的性能这将在下面演示。首先，注意αY的风险由

.

在权力约束下（243），我们有

supR（θ，αY）=（1-α）2c2+α2。

θ∈Θ使右手边最小的α的值是

![img](file:///C:/Users/ADMINI~1/AppData/Local/Temp/msohtmlclip1/01/clip_image145.gif)

其风险由

.

结果表明，在这个问题中，线性估计量α*Y是尖锐的渐近极大极小为了证明这一点，我们将在下面展示

（244）

证明（244）的第一步是在Θ上选择适当的先验w。对w来说最自然的选择可能是在Θ之前的制服但是，使用下面的previor稍微简单一些。设π表示Rn上的Nn（0，δ2c2In）分布，其中δ∈（0，1）。我们取w为π条件下的条件概率测度，即。，

![img](file:///C:/Users/ADMINI~1/AppData/Local/Temp/msohtmlclip1/01/clip_image147.gif)

对于Rn的Borel子集A。设θˆB（w）表示相对于前w的Bayes估计量。注意，由于w在凸集Θ上受支持，估计量θˆB（w）将属于具有概率1的Θ然后我们有了RBayes

贝耶斯。

由于π是Nn（0，δ2c2In）先验，其Bayes风险很容易用封闭形式计算为

亚拜

所以我们得到

亚拜。

现在注意，通过初等不等式ka−bk2≤2kak2+2kbk2，我们得到

.

这给了

![img](file:///C:/Users/ADMINI~1/AppData/Local/Temp/msohtmlclip1/01/clip_image149.gif)

通过柯西-施瓦兹不等式现在在π下，

以便

.

把东西放在一起，我们得到

!

亚拜

因为π（Θ）≤1我们完成了这个论证，我们只需要π（Θc）的下界为此，请注意

.

利用卡方浓度不等式

对于0≤t≤1，

我们得到

! 什么时候。

因此，对于0.5≤δ2≤1，我们得到

亚拜。

因此，我们

liminf RBayes n→∞

这意味着

.

由于δ2∈[0.5,1]是任意的，我们可以让δ2→1得到（244）。这就证明了线性估计量γy的尖锐渐近极大性。

从以上两个尖锐渐近最小轴的例子中，应该清楚的是，这些参数的关键是选择适当的先验W。而且一旦选择了W，参数通常是错综复杂的，因为我们甚至不想在n中丢失常数因子。

接下来我们将研究速率极小值的参数，在失去最小因子的同时，从下界中得到极大极小风险。这些参数简单得多，并且使用离散的prior（通常是参数空间的有限子集上的一致prior）下周我们将研究这些（与多假设检验问题的界有关的）。

# 27讲座27

我们将在今天的讲座中讨论多假设检验问题中的一致Bayes风险下限事实证明，在下一堂课中，一般的决策理论问题中的极小极大风险总是可以由下面的测试风险来限定的，这对于建立利率模型是非常有用的。

## 27.1多假设检验问题

假设我们观察到数据X取空间X中的值（通常，X可以是向量、矩阵、函数等）。对于X的分布，我们有以下N个假设：

H1:X∼P1，H2:X∼P2，…HN:X∼PN。

这里P1，…，PN是X上的概率测度，我们需要根据观测值X选择其中一个假设，检验T是X到{1，…，N}之间的任意函数。给定一个测试T，其类型i误差由i=1，…，n的Pi{T 6=i}定义。我们将根据i=1，…，n的测试类型i误差的平均值来评估测试。

具体来说，让

.

我们可以在一般的决策理论框架下，通过取Θ=A={1，…，N}和L（θ，A）=I{θ6=A}来处理这个问题。在这种情况下，R（T）将简单地是关于Θ之前离散一致性的试验T平均值的平均风险。

很容易看到（如下所示）最大似然检验给出了最小化r（t）的测试t。要了解这一点，让pi表示pi相对于公共支配度量μ的密度我们可以写

.

很容易看出，对于每个测试T和x∈x，我们有

![img](file:///C:/Users/ADMINI~1/AppData/Local/Temp/msohtmlclip1/01/clip_image151.gif)

用t（x）定义的最大似然检验实现相等：＝ARGMAX1±iπ（x）。这证明了T*最小化R（T），并且

（245）

通常很难精确计算B（P1，…，PN）。我们将重点讨论B（P1，…，PN）的下界如后文所述，这些下界将产生一般决策理论问题中极大极小风险的下界。

为了激发B:=B（P1，…，PN）的下界，让我们首先为B提供一个直观的含义。因为B是测试问题中可能的最小平均误差（Bayes风险），所以应该清楚，在某种意义上，它度量概率度量P1，…，PN之间的分离程度。实际上，如果P1，…，PN彼此相距很远，那么测试问题应该更容易，而B将更小另一方面，如果P1，…，PN彼此接近，则测试问题将更难，B将更大还要注意，我们总是有Z

1≤maxpi（x）dμ（x）≤N

我

以便

.

而且，当P1= Fo.= PN时，很容易看出B（P1，…，PN）取最大可能的值1（1／N）。这是有意义的，因为当P1= Fo..Pn时，基于Xπ的I是不可能的，因此测试Bayes风险B（P1，…，PN）取其最大可能的值。

另一方面，当P1，…，Pn是相互奇异的时，B（P1，…，PN）取其最小值0（使得MaXi-Pi= P1+…PN几乎肯定W.R.T）。在这种情况下，可以根据X∼Pi完美地识别i，从而使测试Bayes风险处于其可能的最低值。

B（P1，…，PN）测量P1，…，PN之间分离度的直觉表明，我们可以通过其他自然量来限制它，以测量P1，…，PN的分离度或扩散度。对于实数a1…..aN，最自然的测量它们的分布的方法是它们的方差：

.

我们可以通过定义

)有。（246）

这里的D是指概率度量之间的差异/发散的概念（类似于实数之间的平方欧几里德距离）对D的各种选择是可能的，但最常见的是Kullback-Leibler散度给定两个概率测度P和Q，其密度分别为P和Q，相对于公共支配测度μ，它们之间的Kullback-Leibler散度定义为

![img](file:///C:/Users/ADMINI~1/AppData/Local/Temp/msohtmlclip1/01/clip_image153.gif)

基于上述讨论，应该清楚的是，B（P1，…，PN）和I（P1，…，PN）之间应该存在某种联系（因为两者都在测量P1，…，PN之间的扩散或分离程度）以下引理描述了两者之间的简单关系。这在统计学文献中经常被用来证明极小极大下界，这里它被称为Fano不等式或Fano引理。事实上，这是Fano不等式的一种弱形式；今天晚些时候我们将描述一个强形式。

引理27.1。以下不等式适用于每N≥1和概率测度P1，…，PN：

（247）

引理的证明27.1。这个优雅的证据是由凯普曼[13，135页]提供的。

使用B（P1，…，PN）的公式（245）和I（P1，…，PN）的定义，很明显（247）等于

![img](file:///C:/Users/ADMINI~1/AppData/Local/Temp/msohtmlclip1/01/clip_image155.gif)

很容易看出，这进一步等同于（将上述两边乘以N logN，并使用R（Pi Pi）dμ=N），

![img](file:///C:/Users/ADMINI~1/AppData/Local/Temp/msohtmlclip1/01/clip_image157.gif)

与

![img](file:///C:/Users/ADMINI~1/AppData/Local/Temp/msohtmlclip1/01/clip_image159.gif)

为了证明这一点，显然足以证明以下涉及非负实数的事实对于每一组非负实数a1，…，aN，以下不等式成立：

（248）

为了证明这种不等式，首先我们可以假设，在不损失一般性的情况下，＝1（因此A1，…，AN变为概率向量），A1＝MaXi-AI。不等式（248）等价于

![img](file:///C:/Users/ADMINI~1/AppData/Local/Temp/msohtmlclip1/01/clip_image161.gif)

重新排列为

N个

a1对数（2a1）+Xai对数（2Nai）≥0。

i=2

上述不等式是真的，因为（注意2N≥2（N−1））

.

这就完成了给出（247）的（248）的证明。

## 27.2相互信息

数量I（P1，…，PN）（在（246）中定义）被称为互信息。互信息是信息论中的一个术语。通常定义为一对随机变量Y和Z。形式上，Y和Z之间的互信息I（Y，Z）被定义为Y和Z的联合分布与Y和Z的边际分布乘积之间的Kullback-Leibler散度，

I（Y，Z）：=D（P（Y，Z）kPY×PZ）。

现在考虑两个随机变量Θ和X，使得Θ在{1，…，N}上均匀分布，并且给定的X的条件分布是π。很容易看出

（249）

因此，在（246）中定义的I（P1，…，PN）只是Θ和X之间的互信息。因此，I（P1，…，PN）被称为互信息项因此，Fano不等式给出了相互信息条件下Bayes风险的一个界。

以下关于I（P1，…，PN）的事实将在续集中有用。

引理27.2对于每N≥1和概率测度P1，…，PN，我们有

)（250个）

其中，对所有概率测度取下下确界证明很简单，基于以下身份：

其结果是：

这里∏p=（p1+···+p N）/N是p′相对于μ的密度，q是q相对于μ的密度。

## 27.3稀疏正态均值估计的应用

设n≥1，设Pi为i=1，…，n的Nn（τei，In）分布。这里τ是一个依赖于n的正实数，ei是第i个位置为1，其他位置为0的向量。我们对B：=B（P1，…，Pn）以及它如何依赖于n和τ感兴趣Fano不等式（特别是不等式（247））给出

其中I：=I（P1，…，Pn）。

为了从这里得到一个显式的界，我们需要I的上界。这里引理27.2非常有用，因为它指出

![img](file:///C:/Users/ADMINI~1/AppData/Local/Temp/msohtmlclip1/01/clip_image163.gif)

对于每个概率测度Q，Q的一个自然选择是Q=Nn（0，In）。然后，我们得到（利用D（Nn（μ1，∑）kNn（μ2，∑））=（μ1～（2））T～-1（μ1～（2））/2）

.

这让我们可以推断

（251）

这给出了有趣的推论，例如：

对于τ=plogn。

√

然而，当τ接近λn:=2logn时，不等式（251）不足以产生任何非平凡的结果。例如，当τn：=λn−log（λn）时，则（251）不会给出任何有用的结果。但是，通过直接计算（如下所示），可以表明

=1，当τn=λn-对数（λn）时。（252）

这表明了利用Fano不等式获得B.to证明（252）的下界的一个重要弱点，首先要注意

哪里。

从中我们可以得到

哪里。

因此，如果z1，…，zn是独立的标准正态随机变量，那么

.

为了进一步将这个从下界绑定，我们需要从上面所做的绑定EMAXI E TAZI ZI。

![img](file:///C:/Users/ADMINI~1/AppData/Local/Temp/msohtmlclip1/01/clip_image164.gif)

方法（回忆λn=2logn）：

.

注意，上面的最后一个不等式（Mill的比率界）要求τ<λ因此我们得到

.

对于τ=λ-对数（λ），我们将λ-τ··········。

## 27.4通过数据处理不等式的Fano引理

数据处理不等式是关于Kullback-Leibler散度的一个标准事实它声明如下。假设P和Q是空间X上的两个概率测度，设Γ：X→Y为任意函数。

设PΓ-1表示在映射Γ下的概率测度P的图像，即。，

PΓ-1（A）：=P{j∈A}。

类似地定义QΓ-1数据处理的不平等表明

.

对于每一对概率测度P和Q以及每一个函数Γ，这都是正确的。我们在这里不会给出这个事实的证明（这是标准的，在很多地方都可以找到）我们将在引理27.1中概述Fano不等式的一个简单证明（实际上我们将通过数据处理不等式导出Fano不等式的一个比（247）更强的版本）。

考虑Fano不等式的设置，其中我们有N个概率测度P1，…，PN，在分别具有密度P1，…，PN的空间X上。考虑两个随机变量Θ和X，使得Θ在{1，…，N}上均匀分布，并且给定的X的条件分布为π。设P为Θ和X的联合分布，也设Q为Θ和X的边际分布的乘积的联合分布，我们在（249）中看到

I（P1，…，PN）=D（PkQ）。

现在修复一个测试T，即T是X到{1，…，N}之间的函数然后我们将数据处理不等式应用于由

Γ（j，x）：=I{T（x）6=j}对于j∈{1，…，N}和x∈x。

数据处理不等式将给出

.

现在很容易看出

![img](file:///C:/Users/ADMINI~1/AppData/Local/Temp/msohtmlclip1/01/clip_image166.gif)

和

.

因此，我们已经证明，对于每一个测试T，

.

因为这对于每个测试T都是成立的，所以我们可以取t＝t（最大似然检验，它使r（t）在所有t上最小），使得r（t）＝b＝b（p1，…，pn）。这样就可以

（253）

这种不平等可以看作是法诺不平等的一个更强有力的版本。很容易证明（253）意味着（247）要看到这个，只要注意（253）的右边等于：

![img](file:///C:/Users/ADMINI~1/AppData/Local/Temp/msohtmlclip1/01/clip_image168.gif)

因为infx∈（0,1）（x log x+（1x）log（1x））=-log2和log（N/（N1））≥0。

这种证明Fano不等式（通过数据处理不等式）的一个重要优点是它推广到f-发散f-发散是概率测度之间的一类一般发散，包括作为特例的Kullback-Leibler发散。它们的定义如下。设f：（0，∞）→R是f（1）=0的凸函数然后很容易表明，存在以下限制（即使它们可以是+的）。假设P和Q是空间X上的两个概率测度，其密度P和Q相对于公共支配测度μ。P和Q之间的f-散度用Df（PkQ）表示，定义如下：

.

不同的f选择导致不同的具体分歧例如，KL散度对应于f（x）=xlogx，总变化距离对应于f（x）=| x−1 |/2，平方海林格距离对应于

对于f（x）=1-√x或f（x）=（√x−1）2/2，卡方散度对应于f（x）=x2−1，依此类推。

结果表明，每一个f-散度都满足数据处理不等式。利用这一点，可以证明Fano不等式对每一个f-散度的以下推广：

.

对于f的特定选择，这将导致B的更明确的下界。例如，对于f（x）=x2-1，可以得到

![img](file:///C:/Users/ADMINI~1/AppData/Local/Temp/msohtmlclip1/01/clip_image170.gif)

式中，对于f（x）=x2-1，x2（PkQ）=Df（PkQ）。见Gushchin[10]或Guntuboyina[9]和Chen等人[4]了解更多详细信息。

# 28讲座28

我们将研究通过FANE不等式证明速率极小结果的方法。第一步是通过测试问题中的Bayes风险，从一般决策理论问题中的极大极小风险的下界。

## 28.1经检验的最小最大下界

考虑具有参数空间Θ、作用空间a和非负损失函数L（θ，a）的一般决策理论设置。我们观察到分布属于{Pθ，θ∈Θ}族的数据X。

设F是Θ的有限子集。我们说F是由一个正实数分隔的

inf（L（θ1，a）+L（θ2，a））对于每个θ1，θ2∈F，θ16=θ2≥η。

a∈a

设w表示F上的一致先验，下面的引理表明，当F是η-分离时，Bayes风险RBayes（w）从下有界于（η/2）倍于与概率测度Pθ，θ∈F相对应的测试问题中的Bayes风险。

引理28.1。假设F是分开的。那么

亚拜（254）

请注意

RBayes）和

其中，下确界在RBayes（w）中的所有决策规则d上，在B（{Pθ，θ∈F}）中的所有测试T（即X到F的函数）上。

引理的证明28.1利用L（θ，a）≥（η/2）I{L（θ，a）≥η/2}，我们得到

亚拜。

对于每个决策规则d，我们现在按以下方式关联测试T。将T（x）定义为等于Th，如果存在一个Th f，使得L（Th，d（x））＜2（注意到，因为f是ε-分离的，最多存在一个Th f f，使得L（Th，D（x））＜ε/ 2）。如果没有这样的θ∈F，那么我们把T（X）取为F中的任意点

对于每个θ∈F。

从这里开始，不平等（254）紧接着出现。

在上一类中，我们证明了以下不等式（称为Fano不等式）

.

结合引理28.1和每个先验w的RMinimax≥RBayes（w）的事实，我们得到了以下极大极小下界：

对于每个有限F⊆（255）

我们将在下面看到这一界限的两个例子：稀疏正态均值估计和Lipschitz回归。使用（255）的主要挑战是选择适当的F。

在许多应用中，对于A上的一些伪度量d，A和L（θ，A）=d2（θ，A）

最小d（θ1，θ2）≥τ=？F是（τ2/2）-分离的。（256）

θ1，θ2∈F:θ16=θ2

这是因为对于每一个θ1，θ2∈F和θ16=θ2和a∈a，我们有

.

## 28.2稀疏正态均值估计

考虑由Y∼Nn（θ，in）估计1-稀疏向量θ∈Rn的平方欧氏损失问题这里Θ是Rn中所有1-稀疏向量的类，A=Rn，L（θ，A）是θ和A之间的平方欧氏距离，Pθ是Nn（θ，in）分布。

这里很自然地用√F={τe1，…，τen}来表示一些τ>0（稍后选择）

![img](file:///C:/Users/ADMINI~1/AppData/Local/Temp/msohtmlclip1/01/clip_image171.gif)

kτei-τejk=τ2，对于每个i 6=j，得出F是与η=τ2分开的η（使用（256））。不等式（255）给出

其中I=I（Pθ，θ∈F）上节课我们看到了

这给了

.

取τ2=logn时，RMinimax≥clogn，表示正常数√c（对于n大）这个结果很好

![img](file:///C:/Users/ADMINI~1/AppData/Local/Temp/msohtmlclip1/01/clip_image172.gif)

用La= 2Logn得到软阈值的速率极小。然而，它不够强，不能产生尖锐的渐近极大极小。

## 28.3利普希茨回归

设F表示在绝对值上被1和1-Lipschitz限制的所有函数F:[0，.1]→R的类。考虑从i.i.d观测值（X1，Y1），…，（Xn，Yn）估计f∈f的问题，其中

Xi∼Unif[0,1]和Yi | Xi∼N（f（Xi），1）。

我们取Θ=F，A为[0，1]上所有实值函数的类，并使用损失函数

![img](file:///C:/Users/ADMINI~1/AppData/Local/Temp/msohtmlclip1/01/clip_image174.gif)

我们用Pf表示（X1，Y1），…，（Xn，Yn）的联合分布注意，Pf在[0,1]n×Rn上具有以下密度：

.

我们对最小最大风险感兴趣：

.

可以证明，对于一个普适正常数C，RMinimax≤Cn-2/3。这可以通过研究F上的最小sqaures估计来实现（使用我们之前在类中看到的方法）我们还可以考虑更简单的核回归估计（例如，参见Tsybakov[23，第1章]）。在这里，我们将证明（使用（255））对于正常数c，RMinimax≥cn-2/3。这将特别证明，对于F中的函数估计，最小二乘估计是最小最大速率最优的。

主要的挑战是构造一个合适的F的有限子集F固定一个小的δ>0。对于长度δ[0,1]的闭子区间i，让Ti：i〔0，δ〕表示分段线性帐篷函数，它等于区间I的中点处的最大值δ（特别是i在i的中点处从i的0端到δ线性增加，然后在i的右端点线性减小到0）。现在考虑m间隔：

Ij：=[（j−1）δ，jδ]对于j=1，…，m：=b1/δc&1/δ。

我们现在在F中构造2m个函数，这些函数用τ∈{0,1}m索引，用{Fτ，τ∈{0,1}m}表示具体地说，对于每个τ∈{0,1}m，如果τj=1，我们定义fτ等于区间Ij上的帐篷函数TIj，如果τj=0，则定义fτ等于Ij上的零。此外，每个fτ在∪jIj外等于零。

我们将对这个集合{Pfτ：τ∈{0,1}m}应用（255）。第一步是找到一个合适的值η，F：={Fτ，τ∈{0,1}m}分开。为此，用τ=6τ0固定τ，τ0∈{0,1}m然后τj 6=τj0，对于某些j∈{1，…，m}很容易看出

.

由此（从（256）可知，F与η和δ3分开不平等（255）那么说

其中I：=I（Pfτ，τ∈{0,1}m）。

我们下一步需要把我从上面绑起来。为此，我们将使用

![img](file:///C:/Users/ADMINI~1/AppData/Local/Temp/msohtmlclip1/01/clip_image176.gif)

Q=P0时（即f∏0对应的Pf）。注意，对于两个函数f，g，

![img](file:///C:/Users/ADMINI~1/AppData/Local/Temp/msohtmlclip1/01/clip_image178.gif)

哪里

X1∼统一[0,1]；Y1 | X1∼N（f（X1），1）和X●1∼统一[0,1]；Y●1 | X●1∼N（g（X●1），1）我们也可以计算出

.

因此我们有

![img](file:///C:/Users/ADMINI~1/AppData/Local/Temp/msohtmlclip1/01/clip_image180.gif)

因此I≤nδ2。因此我们有

.

因为m≥c1/δ对于正常数c1，我们有

.

取δ3=（c1 log2）/（2n），我们得到了所有大n的RMinimax&n−1。然而，请注意，我们开始证明RMinimax&n−2/3，因此上述参数得出了RMinimax的次优下界。这个论点变弱的原因是在分离计算中事实上，我们利用了

对于每个τ，τ0∈{0,1}m，其中τ6=τ0。

当τ和τ0仅在一个坐标上不同时（即H（τ，τ0）：=Pj i{τj 6=τj0}正好等于1），也很容易看出上述界限紧到常数乘因子然而，一般来说，fτ和fτ0之间的L2距离取决于H（τ，τ0）很明显

)对于所有τ，τ0∈{0,1}m.（257）

Gilbert Varshamov Lemma（下一步证明）证明了{0,1} m的一个子集W的存在性，其基数为W＞EXP（m／8），并且对于每一个{（4，0）＞m／0，具有0＝T＝0的TAW 0 W。其思想是将（255）应用于F={Fτ：τ∈W}，而不是F={Fτ：τ∈{0,1}m}。上面的不等式（257）以及τ的H（τ，τ0）&m&（1/δ），τ，τ0∈W，τ6=τ0意味着F={Fτ：τ∈W}与η&δ2分开相互之间的信息边界保持不变。我们会得到

.

选择δ3=（c1 log2）/（2n）将给出所有大n的RMinimax&n−2/3。

## 28.4 Gilbert-Varshamov引理

引理28.2对于每m m 1，存在{0,1} m的一个子集W，其基数W＞Exp（m／8），使得每一个顶点的H（TAU，TAL 0）＞M／4，TAW 0＝TH0＝0。

证明。这里将使用以下基本概率界：

（258）

要证明（258），请注意（第一个等式遵循对称性）

.

取λ=log3，我们得到

.

现在设W是{0,1} m的最大子集，对于每一个顶点，H（TAU，TAU 0）＞M／4，TAW 0＝W，其中TAU 6＝TAI 0。这里的最大值意味着如果{0,1} M的任何其他元素被加到W，则分离条件将被违反。这意味着[BH（TAG，M/4）＝{0,1} M，其中B（TAm，M/4）：{{ω{0,1}M:H（TAG，ω））小于m/4 }h。

τ∈W

以便

2m=X | BH（τ，m/4）|≤| W | max | BH（τ，m/4）|（259）

τ∈W

τ∈W现在对于每个A⊆{0,1}m，我们有

|A|=2mP{（T1，…，Tm）∈A}，其中T1，…，Tm是i.i.d Ber（1/2）。

因此

2-m | BH（τ，m/4）|=P{（T1，…，Tm）∈BH（τ，m/4）}

（米）

=P XI{Ti 6=τi}≤m/4=P{Bin（m，1/2）≤m/4}≤exp（m/8）。

i=1

不等式（259）立即给出| W |≥exp（m/8），从而完成引理28.2的证明。

## 28.5避免F的显式构造的Yang-Barron方法

如前所述，应用（255）的主要困难是构造Θ的有限子集F。Yang和Barron[26]有一个避免F的显式构造的好主意，前提是可以得到关于包装和覆盖数Θ的结果下面是这个想法背后的细节。

对于ε＞0，假设n（ε，ε）是任意正实数，因此存在一个具有基数f（n，ε）的ε-分离有限子集F。将不等式（255）应用于这样一个F，我们得到

（260）

我们现在用下面的方法从上面对I=I（{Pθ，θ∈F}）进行定界我们知道

)（261）

对于X上的每个概率测度Q，假设Q1，…，Q M是X上的任意概率测度，并应用（261），Q=Q’=（Q1+···+QM）/M，这给出了

.

现在对于每个θ∈F，如果q1，…，qM分别表示q1，…，qM w.r.tμ的密度（而pθ表示pθw.r.tμ的密度），那么

![img](file:///C:/Users/ADMINI~1/AppData/Local/Temp/msohtmlclip1/01/clip_image182.gif)

现在每1≤j≤M，我们就有q1+···+qM≥qj

![img](file:///C:/Users/ADMINI~1/AppData/Local/Temp/msohtmlclip1/01/clip_image184.gif)

因为这对于每1≤j≤M是真的，我们推断

D（PθkQ’）≤min D（PθkQj）+logM。

1≤j≤M

因为这对于每个θ∈F都是正确的，所以我们得到

![img](file:///C:/Users/ADMINI~1/AppData/Local/Temp/msohtmlclip1/01/clip_image186.gif)

0和Θ的子集S，let）表示X上概率测度Q1，…，QM的最小数M，使得

.

上面的论证给出了

)为每一个人。

利用（260）中的这个界，我们得到，对于每个η>0和>0，

.

不等式Θ（这仅在以下情况下有用）给出

（262）

这个界的优点是它只依赖于Θ的性质。例如，在Lipschitz回归例子中，已知（第6课）在L2度量下F的包装数（这里F是[0,1]上所有实值函数的类，它们是1-Lipschitz且有1的边界）满足：

.

使用这个，很容易证明我们可以

和日志

在（262）。这给了

.

从这里取和η∼n−2/3（并适当调整基础常数），我们可以立即得到RMinimax&n−2/3。注意，此参数中没有使用有限子集F的显式构造（这项工作隐式地在包装数界限的证明中完成）。

更一般地，回想一下第6课中的平滑度等级Sdα。考虑从n i.i.d观测值（X1，Y1），…，（Xn，Yn）对函数f∈Sd，α的估计

Xi∼Unif[0,1]和Yi | Xi∼N（f（Xi），1）。

考虑[0,1]d上的积分L2损失函数：

Z轴

L（f，g）=（f（x）–g（x））2倍。

[0,1]天

在这种情况下，使用Sd，α的包装数满足的事实（在第6课中陈述）：

,

我们可以（这里的常数都取决于d）

和日志

在（262）这给了

.

取η=n−2α/（2α+d），我们得到

RMinimax≥n−2α/（2α+d）。

# 工具书类

[1]     Baraniuk，R.，M.Davenport，R.DeVore和M.Wakin（2008年）随机矩阵限制等距性质的一个简单证明。施工约28（3），253–263。

[2]     比林斯利，P.（1968）概率测度的收敛性。纽约：威利。

[3]     Boucheron，S.，G.Lugosi和P.Massart（2013年）。集中不平等：一个非共同性的独立理论。牛津大学出版社。

[4]     Chen，X.，A.Guntuboyina和Y.Zhang（2016年）。关于Bayes风险下限。机器学习研究杂志17（219），1-58。

[5]     达德利，R.M.（1989）真实分析和概率加州贝尔蒙特：沃兹沃斯。

[6]     达德利，R.M.（1999）。一致中心极限定理剑桥大学出版社。

[7]     Feller，W.（1968年）概率论及其应用导论（第三版），第一卷。纽约：威利。

[8]     Ferguson，T.S.（1967年）数理统计：一种决策理论方法。波士顿：学术

按。

[9]     Guntuboyina，A.（2011年）。利用f-发散的极大极小风险下界及其应用关于信息理论的IEEE交易572386-2399。

[10]  Gushchin，A.A.（2003年）。关于Fano引理和极大极小风险的类似不等式。西奥。概率和数学。统计学家。67、29-41岁。

[11]  约翰斯顿，I.M.（2017）高斯估计：序列和小波模型。手稿，2017年8月。可在

[12]  加藤，K.（2017）经验过程理论课堂讲稿可在

[13]  Kemperman，J.H.B.（1969年）论信息的最佳传输速率。在概率论和信息论中斯普林格·维拉格。数学课堂讲稿，89，第126-169页。

[14]  Le Cam，L.（1986年）。统计决策理论中的渐近方法。纽约：斯普林格·维拉格。

[15]  Le Cam，L.和G.L.Yang（2000年）。统计学中的渐近线：一些基本概念（第2版）。斯普林渥弗拉格。

[16]  Mendelson，S.和R.Vershynin（2003年）。熵与组合维数。发明数学152，37-55。

[17]  Oymak，S.和B.Hassibi（2013年）。用于近去噪的尖锐MSE边界。计算数学基础，1-65。

[18]  波拉德，D.（1984）。随机过程的收敛性。纽约：斯普林格。

[19]  Pollard，D.（1997年）。再看二次均值的可微性在D.Pollard，E.Torgersen和G.L.Yang（编辑），Lucien Le Cam的Festschrift，第305-314页。纽约：斯普林格·维拉格。

[20]  Pollard，D.（2001年）。测量理论概率的用户指南剑桥大学出版社。

[21]  Rudelson，M.和R.Vershynin（2006年）。随机过程和凸体截面的组合数学。数学年鉴，603-648。

[22]  Talagrand，M.（1996年）。重新审视独立。概率年鉴24，1-34。

[23]  Tsybakov，A.（2009年）。非参数估计导论斯普林格·维拉格。

[24]  Van der Vaart，A.（1998年）。渐近统计。剑桥大学出版社。

[25]  Van der Vaart，A.和J.A.Wellner（1996年）弱收敛与经验过程：在统计学中的应用。斯普林格·维拉格。

[26]  Yang，Y.和A.Barron（1999年）。极小极大收敛速度的信息论确定。统计年鉴271564-1599。