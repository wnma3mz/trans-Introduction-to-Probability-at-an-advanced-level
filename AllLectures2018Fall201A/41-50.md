# 1                最佳线性预测

考虑具有有限方差的随机变量Y，X1，…，Xp。我们想在X1，…，Xp的基础上预测Y。给定基于X1，…，Xp的Y的预测因子g（X1，…，Xp），我们通过

R（g）：=E（Y-g（X1，…，Xp））2。

我们在上一节课中看到，最佳预测因子（即使R（g）最小化的函数g*由条件期望给出：

g∗（x1，…，xp）：=E（Y | x1=x1，…，xp=xp）。

这种有条件的期望往往是一个相当复杂的量。例如，在实际估计中，需要大量关于变量X1，…，Xp，Y的数据。

我们现在考虑一个相关的问题，仅基于X1，…，Xp的线性函数来预测Y。具体而言，我们考虑β0+β1X1+····+βp X p=β0+βT X形式的预测（其中β：=（β1，…，βp）T和X=（X1，…，Xp）T）就X1，…，Xp而言，Y的最佳线性预测（BLP）是线性函数

具有

哪里最小化

L（β0，…，βp）=E（Y-β0-β1X1-····-βpXp）2

超过β0，β1，…，βp。

通过微积分直接使L最小，可以得到和β*的显式公式取关于β0，β1，…，βp的偏导数，并将其设为零，我们得到以下方程：

)=0（68）

和

=0，i=1，…，p.（69）

上面的第一个方程意味着这是一个均值为零的随机变量。利用这个，我们可以将第二个方程重写为

)=0表示i=1，…，p

这和

)=0，i=1，…，p.（70）

重新排列上面的内容，我们得到

第页

X∗

βi Cov（Xi，Xj）=i=1，…，p时的Cov（Y，Xi）。

j=1

在矩阵表示法中，我们可以将其重写为

Cov（X）β∗=Cov（X，Y）与。

这里Cov（X，Y）是p×1向量，有项Cov（X1，Y），…，Cov（Xp，Y）。上面的公式给出了

β∗=（Cov（X））-1 Cov（X，Y）

假设Cov（X）是可逆的这个方程决定了我们可以用（73）来写

.

注意，上面出现的术语Cov（Y，X）是Cov（X，Y）的转置更一般地，给定两个随机向量W=（W1，…，W p）和Z=（Z1，…，Z q），我们将Cov（W，Z）定义为p×q矩阵，其（i，j）项是Wi和Zj之间的协方差。

根据X1，…，Xp，Y的最佳线性预测（BLP）等于

β0∗+β1∗X1+…βp∗Xp=β0∗+（β∗）TX

=E（Y）–Cov（Y，X）（Cov（X））–1E（X）+Cov（Y，X）（Cov（X））–1X

=E（Y）+Cov（Y，X）（Cov（X））-1（X−E（X））（71）

如前所述，就X1，….Xp而言，Y的最佳预测因子（BP）是X1，….Xp的函数g∗（X1，…，Xp），它使

L（g）：=E（Y-g（X1，…，Xp））2

在所有函数g中我们都看到了

g∗（X1，…，Xp）=E（Y | X1，…，Xp）。

换句话说，最好的预测因素是条件期望。一般来说，BP和BLP是不同的，与BLP相比，BP对Y的预测更准确。注意，BLP只依赖于随机变量Y，X1，…，Xp之间的方差和协方差，而BP则潜在地依赖于整个联合分布。因此，与BP相比，BLP通常更容易根据数据进行估计。

一般来说，我们将把任何涉及Y，X1，…，Xp分布的量作为二阶性质，它只依赖于Y，X1，…，Xp的均值、方差和协方差。请注意，BLP是第二个订单数量，而BP不是。

# 2                最佳线性预测

在上一堂课中，我们讨论了基于其他随机变量X1，…，Xp的线性函数预测随机变量Y的问题。具体而言，我们考虑β0+β1X1+····+βp X p=β0+βT X形式的预测（其中β：=（β1，…，βp）T和X=（X1，…，Xp）T）。就X1，…，Xp而言，Y的最佳线性预测（BLP）是线性函数

具有

哪里最小化

L（β0，…，βp）=E（Y-β0-β1X1-····-βpXp）2（72）

超过β0，β1，…，βp。

设置（72）相对于β0，…，βp的导数，并将其设置为零，我们观察到满足以下方程：

)=0（73）

和

)=0，i=1，…，p.（74）

（74）中的方程式可以用矩阵表示法简洁地写成：

Cov（X）β∗=Cov（X，Y）与。

这里Cov（X，Y）是p×1向量，有项Cov（X1，Y），…，Cov（Xp，Y）。上面的公式给出了

β∗=（Cov（X））–1个Cov（X，Y）这就决定了我们可以用（73）来写

.

注意，上面出现的术语Cov（Y，X）是Cov（X，Y）的转置更一般地，给定两个随机向量W=（W1，…，W p）和Z=（Z1，…，Z q），我们将Cov（W，Z）定义为p×q矩阵，其（i，j）项是Wi和Zj之间的协方差。

Y的最佳线性预测（BLP）X1，…，Xp等于β0∗+β1∗X1+…βp∗Xp=β0∗+（β∗）TX

=E（Y）–Cov（Y，X）（Cov（X））–1E（X）+Cov（Y，X）（Cov（X））–1X

=E（Y）+Cov（Y，X）（Cov（X））-1（X−E（X））（75）

以下是BLP的一些重要特性：

\1.    BLP求解方程（73）和（74）。这些方程称为正规方程。

\2.    如果Cov（X）是可逆的（等价地，正定的），那么BLP由（75）唯一给出。

\3.    Y-BLP的平均值为零（因为（73）），Y-BLP与每个Xi不相关，i=1，…，p（因为（74））事实上，这个属性是BLP的特征（见下一步）。

\4.    如果Cov（X）是可逆的，那么从正态方程的形式可以清楚地看出，BLP是X1，…，Xp的唯一线性组合，使得Y-BLP具有平均零，并且与X1，…，Xp不相关。

例42.1（情况p=1）当p=1时，随机向量X只有元素X1，因此Cov（X）刚好等于V ar（X1）在这种情况下，Y关于X1的BLP由

.

换句话说，当p=1时，

.

在进一步的特殊情况下，当V ar（Y）=V ar（X1）和E（Y）=E（X1）=0时，我们有

![img](file:///C:/Users/ADMINI~1/AppData/Local/Temp/msohtmlclip1/01/clip_image002.gif)

所以BLP是由ρY，X1X1给出的。

例42.2。假设X1，X2，Z3，…，Zn，Zn+1是不相关的随机变量和均值为零的随机变量将随机变量X3，…，Xn+1定义为

对于t=3，…，n+1，Xt=φ1Xt-1+φ2Xt-2+Zt。

当n≥2时，Xn+1在X1，…，Xn的BLP是多少？

根据定义，

Xn+1=φ1Xn+φ2Xn−1+Zn+1

也就是说Xn+1-φ1Xn-φ2Xn-1=Zn+1现在很容易看出，对于t≥3，每个Xt仅依赖于X1，X2，Z3，…，Zt，这意味着Zn+1与所有X1，…，Xn不相关。

因此，φ1Xn+φ2Xn-1是X1，…，Xn的线性组合，使得Xn+1-φ1Xn-φ2Xn-1与X1，…，Xn中的每一个都不相关（它也具有平均零）。因此，我们推断Xn+1的BLP在X1，…，Xn方面等于φ1Xn+φ2Xn-1。

如前所述，就X1，….Xp而言，Y的最佳预测因子（BP）是X1，….Xp的函数g∗（X1，…，Xp），它使

L（g）：=E（Y-g（X1，…，Xp））2

在所有函数g中我们都看到了

g∗（X1，…，Xp）=E（Y | X1，…，Xp）。

换句话说，最好的预测因素是条件期望。一般来说，BP和BLP是不同的，与BLP相比，BP对Y的预测更准确。注意，BLP只依赖于随机变量Y，X1，…，Xp之间的方差和协方差，而BP则潜在地依赖于整个联合分布。因此，与BP相比，BLP通常更容易根据数据进行估计。

一般来说，我们将把任何涉及Y，X1，…，Xp分布的量作为二阶性质，它只依赖于Y，X1，…，Xp的均值、方差和协方差。请注意，BLP是第二个订单数量，而BP不是。

# 3                残差

随机变量Y在X1，…，Xp方面的余数将用rY | X1，…，Xp表示，并定义为Y与Y的BLP在X1，…，Xp方面的差异换句话说，

rY | X1，…，Xp=Y−BLP。

使用BLP的公式，我们可以为残差写下以下公式：

rY | X1，…，Xp=Y−E（Y）–Cov（Y，X）（CovX）–1（X−E（X））（76）

其中X是p×1随机向量，分量为X1，…，Xp。

残差的均值为零，与X1，…，Xp中的每一个都不相关。这可以直接从公式（76）或从BLP的性质来证明。

残差的方差可由公式（76）计算如下：

![img](file:///C:/Users/ADMINI~1/AppData/Local/Temp/msohtmlclip1/01/clip_image004.gif)

换言之，V ar（rY | X1，…，Xp）等于协方差矩阵中V ar（Y）的Schur补码（下一次调用）：

![img](file:///C:/Users/ADMINI~1/AppData/Local/Temp/msohtmlclip1/01/clip_image006.gif)

（n+1）×1随机向量（X1，…，Xp，Y）T。

注意，剩余量也是第二个订单数量。

# 4                绕道：Schur补语

假设一个n×n矩阵A被分成四个块

![img](file:///C:/Users/ADMINI~1/AppData/Local/Temp/msohtmlclip1/01/clip_image008.gif)

其中E为p×p，F为p×q，G为q×p，H为q×q（p和q为p+q=n）。

我们定义

ES:=E-FH-1G和HS:=H-GE-1F

假设H 1和E 1存在。我们将把ES和HS分别称为E和H的Schur补语（警告：这不是标准术语；更常见的说法是把ES称为H的Schur补语，把HS称为E的Schur补语。我觉得把ES看作E的Schur补语和HS看作H的Schur补语更自然）。

注意E和ES都是p×p，而H和HS都是q×q。

Schur补语有许多有趣的性质，例如：

\1.    det（A）=det（E）det（HS）=det（H）det（ES）。

\2.    如果A是正定的，那么E，ES，H，HS都是正定的。

还有很多其他人请随意阅读Diane Ouellette的专著《Schur Completions and Statistics》，以证明和阐述这些事实（这对本课程并不一定）。

但Schur补的一个非常重要的性质是它们自然地出现在分块矩阵的逆矩阵中。分块矩阵的逆矩阵的标准公式（例如，参见

（77个）

必须从这个公式中注意到，A-1的第一个（或（1,1）第块等于A的第一个块的Schur补的逆。同样，A-1的最后一个（或（2,2）第块等于A的最后一个块的Schur补的逆。

我们将使用表达式（77）来求分块矩阵A的逆，但我们不知道如何证明（77）。你可以在其他地方找到这一事实的许多证据（只是谷歌类似于“分区矩阵的逆”）。

# 5                偏相关

给定随机变量Y1，Y2和X1，…，Xp，给定X1，…，Xp的Y1和Y2之间的偏相关用ρY1，Y2 | X1，…，Xp表示，定义为

.

换句话说，ρY1，Y2 | X1，…，Xp被定义为给定X1，…，Xp的Y1的余数与给定X1，…，Xp的Y2的余数之间的相关性。ρY1，Y2 | X1，…，Xp也被称为Y1和Y2在控制X1，…，Xp后的偏相关由于残差是二阶量，因此偏相关也是二阶量我们现在来看看如何用Y1，Y2和X的协方差来显式地写出偏相关。

如rY1 | X1，…，Xp=Y1−E（Y1）–Cov（Y1，X）（CovX）–1（X−E（X））

和rY2 | X1，…，Xp=Y2−E（Y2）–Cov（Y2，X）（CovX）–1（X−E（X）），

可以检查（作为练习留下）

Cov（rY1 | X1，…，Xp，rY2 | X1，…，Xp）=Cov（Y1，Y2）–Cov（Y1，X）（CovX）–1Cov（X，Y2）。

这与前一小节的残差方差公式一起，给出了偏相关ρY1，Y2 | X1，…，Xp的以下公式：

.

当p=1，使X等于标量随机变量X1时，上述公式简化为（勾选此项）：

.

把残差rY1 | X1，…，Xp和ry2 | X1，…，Xp的方差及其协方差放在矩阵中是有指导意义的。首先回顾一下：

V ar（rY1 | X1，…，Xp）=V ar（Y1）–Cov（Y1，X）（CovX）–1Cov（X，Y1），

V ar（rY2 | X1，…，Xp）=V ar（Y2）–Cov（Y2，X）（CovX）–1Cov（X，Y2）

和

Cov（rY1 | X1，…，Xp，rY2 | X1，…，Xp）=Cov（Y1，Y2）–Cov（Y1，X）（CovX）–1Cov（X，Y2）。

设RY1，Y2 | X1，…，Xp表示由残差RY1 | X1，…，Xp和rY2 | X1，…，Xp组成的2×1随机向量。残差的方差和协方差公式允许我们将RY1，Y2 | X1，…，Xp的2×2协方差矩阵写成

![img](file:///C:/Users/ADMINI~1/AppData/Local/Temp/msohtmlclip1/01/clip_image010.gif)

哪里

X1

X2

 · 



和X=·。

 · 

经验值

Cov公式的右边（RY1，Y2 | X1，…，Xp）正好等于矩阵中Cov（Y）的Schur补

.

因此，如果∑表示（p+2）×1随机向量（X1，…，Xp，Y1，Y2）T的协方差矩阵，那么Cov（RY1，Y2 | X1，…，Xp）正好等于∑中Cov（Y）的Schur补我们将在下一节课中回到这个事实，并用它来描述一个涉及∑-1的偏相关ρY1，Y2 | X1，…，Xp的表达式。

# 6                偏相关与反协方差

上节课我们定义了偏相关给定随机变量Y1，Y2和X1，…，Xp，给定X1，…，Xp的Y1和Y2之间的偏相关用ρY1，Y2 | X1，…，Xp表示，定义为

.

换句话说，ρY1，Y2 | X1，…，Xp被定义为给定X1，…，Xp的Y1的余数与给定X1，…，Xp的Y2的余数之间的相关性。

记住，残差rY1 | X1，…，Xp和rY2 | X1，…，Xp有以下表达式：

rY1 | X1，…，Xp=Y1-E（Y1）-Cov（Y1，X）（CovX）-1（X-E（X））

和rY2 | X1，…，Xp=Y2−E（Y2）–Cov（Y2，X）（CovX）–1（X−E（X）），

在上一个类中，我们计算了rY1 | X1，…，Xp和rY2 | X1，…，Xp的方差以及它们之间的协方差这给了我们公式：

V ar（rY1 | X1，…，Xp）=V ar（Y1）–Cov（Y1，X）（CovX）–1Cov（X，Y1），

V ar（rY2 | X1，…，Xp）=V ar（Y2）–Cov（Y2，X）（CovX）–1Cov（X，Y2）

和

Cov（rY1 | X1，…，Xp，rY2 | X1，…，Xp）=Cov（Y1，Y2）–Cov（Y1，X）（CovX）–1Cov（X，Y2）。

我们可以把这些表达式放在一起，得到给定X1，…，Xp的Y1和Y2之间的偏相关的下列公式：

.

现在我们将描述部分相关和协方差矩阵的逆之间的关系。

设RY1，Y2 | X1，…，Xp表示由残差RY1 | X1，…，Xp和rY2 | X1，…，Xp组成的2×1随机向量残差的方差和协方差公式允许我们将RY1，Y2 | X1，…，Xp的2×2协方差矩阵写成

![img](file:///C:/Users/ADMINI~1/AppData/Local/Temp/msohtmlclip1/01/clip_image012.gif)

哪里

X1

X2



而X=·····································。

 · 

经验值

Cov公式的右边（RY1，Y2 | X1，…，Xp）正好等于矩阵中Cov（Y）的Schur补

.

因此，如果∑表示（p+2）×1随机向量（X1，…，Xp，Y1，Y2）T的协方差矩阵，那么Cov（RY1，Y2 | X1，…，Xp）正好等于∑中Cov（Y）的Schur补。

但是我们知道如果我们反转∑，那么∑-1的最后一个对角线块（或第（2,2）个块）等于∑的第（2,2）个块的Schur补的逆Schur补和RY1，Y2 | X1，…，Xp的协方差之间的上述联系允许我们推断

![img](file:///C:/Users/ADMINI~1/AppData/Local/Temp/msohtmlclip1/01/clip_image014.gif)

然后

![img](file:///C:/Users/ADMINI~1/AppData/Local/Temp/msohtmlclip1/01/clip_image016.gif)

然后给出了2×2矩阵逆的一般公式

![img](file:///C:/Users/ADMINI~1/AppData/Local/Temp/msohtmlclip1/01/clip_image018.gif)

其中D是Cov的行列式（RY1，Y2 | X1，…，Xp）。

由此可知，偏相关ρY1，Y2 | X1，…，Xp有另一个表达式：

.

这表明了部分相关矩阵和逆协方差矩阵之间的联系。

更一般地，如果Y1，…，Yn是随机变量（这里不需要分布假设），协方差矩阵由∑给出。那么给定Yk，k 6=i，k6=j，Yi和Yj之间的偏相关可以用∑-1写成

.

这尤其意味着

（？-1）（i，j）=0⇐•？ρYi，Yj | Yk，k6=i，k6=j=0

因此，当Yk，k 6=i，k6=j为0时，（？-1）（i，j）=0等于Yi和Yj之间的偏相关。

阿尔索

（σ-1）（i，j）≤0⇐ρYi，Yj | Yk，k6=i，k6=j≥0和（σ-1）（i，j）≥0⇐ρYi，Yj | Yk，k6=i，k6=j≤0

换言之，当Yk，k 6=i，k6=j为非负时，∑-1（i，j）为非正态，相当于Yi与Yj之间的偏相关。类似地，当Yk，k 6=i，k6=j为非正时，∑-1（i，j）为非负相当于Yi和Yj之间的偏相关。

# 7                偏相关与最佳线性预测

考虑随机变量Y和X1，…，Xp用X1，…，Xp表示Y的BLP。

我们之前已经看到，如果p=1，那么X等于标量随机变量X1，BLP则具有表达式：

.

换句话说，当p=1时，BLP的斜率系数由

（78）

当p≥1时，我们将得到p“斜率”系数X1，…，Xp。在这种情况下，可以写出类似于（78）的公式，如下所示：

（79个）

也就是说，根据rXi | Xk，k6=i等于rY | Xk的BLP的斜率系数。

我们现在要证明这一事实。我们可以假设在不丧失一般性的情况下i=p。对其他i的证明可以通过重新排列X1，…，Xp来完成，这样Xi出现在最后一个位置。β∗=（β1，…，βp）∗的公式是

.

让我们写信

式中，X-p：=（X1，…，Xp-1）T由除Xp以外的所有X组成我们可以将Cov（X）划分为

.

然后β*的公式变成

![img](file:///C:/Users/ADMINI~1/AppData/Local/Temp/msohtmlclip1/01/clip_image020.gif)

为了从这个表达式导出的显式公式，我们需要计算（CovX）－1的最后一行分块矩阵的逆矩阵的标准公式表明

一些东西

式中，HS:=H-GE-1F是A中H的Schur补码。我们将此公式应用于

E=Cov（X−p），F=Cov（X−p，X p），G=Cov（Xp，X−p），H=V ar（Xp）

所以A等于Cov（X）。在这种情况下，

HS=V ar（X p）－Cov（Xp，X－p）（Cov（X－p））－1Cov（X－p，Xp）＝V ar（rXp | Xk，k6＝p）

以便

.

因此我们得到

.

这证明了i=p的结果，一个可以证明另一个i的结果，只要重新排列X1，…，Xp，使Xi显示为最后一个变量。

（79）的一个重要结果是：

=0（80）

换句话说，当且仅当Y与Xi之间的偏相关系数Xk，k 6=i等于0时，基于X1，…，Xp的Y的BLP中的Xi系数等于零。

例47.1。假设n≥2的X1，X2，Z3，…，Zn，Zn+1是均值为零的不相关随机变量将随机变量X3，…，Xn+1定义为

对于t=3，…，n+1，Xt=φ1Xt-1+φ2Xt-2+Zt。

在上一个类中，我们已经看到Xn+1的BLP，就X1，…，Xn等于φ1Xn+φ2Xn-1这意味着Xn+1的BLP中Xi的系数X1，…，Xn等于0，对于i=1，…，n-2作为（80）的结果，我们推断

ρXn+1，Xi | Xk，k6=i，i=1，…，n-2时，1≤k≤n=0。

利用偏相关和逆协方差的关系，我们可以进一步推导出如果∑表示X1，…，Xn+1的（n+1）×（n+1）协方差矩阵，则

当i=1，…，n-2时，∑-1（i，n+1）=0。

# 8                当Y是随机向量时的BLP

让我们先快速回顾一下BLP。给定随机变量Y和X1，…，Xp，Y的线性预测因子X1，…，Xp是β0+β1X1+···+βpXp形式的随机变量。BLP由where minimize给出：

L（β0，β1，…，βp）：=E（Y−β0−β1X1——···−βpXp）2

在β0，…，βp上，我们已经看到可以用微积分计算出来，这给出了公式：

BLP=EY+Cov（Y，X）（CovX）–1（X–EX）

其中X代表p×1随机向量，分量X1，…，Xp。剩余的rY | X1，…，Xp简单地等于Y-BLP，我们已经看到rY | X1，…，Xp的方差等于：

var（rY | X1，…，Xp）=var（Y）–Cov（Y，X）（CovX）–1Cov（X，Y）。

注意，这是

现在假设我们有两个随机变量Y1和Y2，Y表示2×1随机向量，分量Y1和Y2。考虑根据X求Y的BLP的问题（其中X，如前所述，是p×1随机向量，分量X1，…，Xp）为了形式化，我们首先需要定义什么是线性预测（注意Y是2×1随机向量，而不是标量随机变量）。根据X给出Y的线性预测

斧头+c

其中A是2×p矩阵，c是2×1向量。预测Y的线性预测器的精度可以通过

L（A，c）：=EkY–-AX–-ck2。

然后由A*Y+c*给出BLP，其中A*和c*将A和c上的L（A，c）最小化。为了解决这个最小化问题，让我们先将A和c写成

和

以便

![img](file:///C:/Users/ADMINI~1/AppData/Local/Temp/msohtmlclip1/01/clip_image022.gif)

和

L（A，c）=EkY–-AX–-ck2=E（Y1–-a11X1–-a12X2–··–-a1pXp–-c1）2+E（Y2–-a21X1–-a22X2–··–-a2pXp–-c2）2

从这里可以清楚地看出，为了使上述关于A和c的最小，我们可以将a11，a12，…，a1p，c1上的第一项最小化，然后将a21，a22，…，a2p，c2上的第二项最小化从这里很容易看到

以X表示的是

就Y2的BLP而言

因此，即使Y是2×1随机向量，相同的公式EY+Cov（Y，X）（CovX）－1（X－EX）也会根据X给出Y的BLP。现在很容易看出，当Y是k×1的随机向量时，对于每个k≥1（而不仅仅是k=1或k=2），这是成立的可以用X1，…，Xp定义Y的余数

Y | X：=Y−EY−Cov（Y，X）（CovX）–1（X−EX）

这正是向量，它的第i个分量是Yi在X1，…，Xp方面的余数。检查RY | X的协方差矩阵是否由

Cov（RY | X）=Cov（Y）–Cov（Y，X）（CovX）–1Cov（X，Y）

也就是矩阵中Cov（Y）的Schur补

# 9                随机向量的矩母函数

接下来我们将讨论这门课的最后一个主题：多元正态分布。因此，了解随机向量的矩母函数是很有帮助的。

n×1随机向量Y的矩母函数定义为

阿蒂

我的（a）：=Ee

对于期望存在的每一个RN。注意，当a=（0，…，0）T是零向量时，很容易看到MY（a）=1。

就像在单变量情况下，矩生成函数在A＝0的邻域中确定分布。

矩生成函数在独立的情况下表现得非常好。假设Y（1）和Y（2）是两个随机向量，设为将Y（1）和Y（2）放在同一列向量中得到的向量。那么Y（1）和Y（2）是独立的当且仅当

我的（a）=我的（1）（a（1））我的（2）（a（2））对于每个。

因此在独立性下，MGF分解，反之，当MGF分解时，我们有独立性。

# 10          多元正态分布

多元正态分布的定义如下。

定义50.1。随机向量Y=（Y1，…，Yn）T是多元正态分布，如果Y的每一个线性函数都是单变量正态分布。

备注50.1。必须强调的是，要使Y=（Y1，…，Yn）T为多元正态函数，Y=a1Y1+…anYn的每个线性函数都需要为单变量正态函数举个例子来说，仅仅让每个Yi成为单变量正态是不够的很容易构造这样的例子，其中每个Yi都是单变量正规，但是对于许多向量（a1，…，a N）T，a1 Y1+·····+anYn不是单变量正规。例如，假设Y1∼N（0,1）和Y2=ζY1，其中ζ是离散随机变量，取概率为1/2的两个值1和−1，且ζ独立于Y1。很容易看出

Y2 |ζ=1∼N（0,1）和Y2 |ζ=-1∼N（0,1）。

因此，这意味着Y2∼N（0,1）（并且Y2独立于ζ）。但是请注意，Y1+Y2不是正常的

.

因此，在这个例子中，即使Y1和Y2都是N（0,1），向量也不是多元正态的。

例50.2。我们在前面的课中已经看到，如果Z1，…，Zn是独立的单变量正态分布，那么a1Z1+…anZn是每个a1，…，an的正态分布。因此，由独立正态随机变量组成的随机向量Z=（Z1，…，Zn）T具有多元正态分布。事实上，我们将在下面证明，如果Y有一个多元正态分布，那么它必然是

Y是由独立的单变量正态随机变量构成的随机向量Z的线性函数。

## 10.1         多元正规的矩母函数

假设Y=（Y1，…，Yn）T是多元正态分布。设μ=E（Y）和∑=Cov（Y）分别为Y的均值向量和协方差矩阵然后，作为多元正态性定义的直接结果，Y的MGF等于

（81）

要了解为什么这是真的，请注意，根据多元正态性的定义，aTY是单变量正态的现在aTY的均值和方差由

E（aT Y）=在μ和V ar（aTY）=aTCov（Y）a=在∑a

以便

aTY∼N（aTμ，aT∑a）表示每一个a∈Rn。

然后（81）直接从一元正规的MGF公式得出。

注意Y的MGF（由（81）给出）仅取决于Y的平均向量μ和协方差矩阵∑。因此，每个多元正态向量Y的分布特征是平均向量μ和协方差∑。因此，我们使用符号Nn（μ，σ）表示平均μ和协方差∑的多元正态分布。

## 10.2         与i.i.d N（0,1）随机变量的连接

假设Y的协方差矩阵∑是正定的，所以∑-1/2是定义良好的设Z：=∑-1/2（Y-μ）。公式（81）允许计算Z的MGF，如下所示：

.

上面的右手边显然是一个随机向量的MGF，这个随机向量具有n i d标准正态随机变量因此，由于MGFs唯一地决定分布，我们得出结论Z=（Z1，…，Zn）T具有独立的标准正态随机变量。因此，我们证明了：如果Y∼Nn（μ，∑）和∑是p.d，那么Z=的Z1，….Zn是独立的标准正态随机变量。