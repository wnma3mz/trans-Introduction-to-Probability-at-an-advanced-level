# 1                多元正态分布的联合密度

假设Y=（Y1，…，Yn）T是具有多元正态分布的随机向量。那么Y1，…，Yn的节理密度是多少？

设μ=E（Y）和∑=Cov（Y）分别为Y的均值向量和协方差矩阵为了使Y有一个连接密度，我们需要假设∑是正定的在上一节中，我们看到Z的Z1，…，Zn是独立的标准正态随机变量，其中

Z=∑-1/2（Y–）。

因为Z1，…，Zn是独立的标准法线，它们的关节密度等于

![img](file:///C:/Users/ADMINI~1/AppData/Local/Temp/msohtmlclip1/01/clip_image002.gif)

式中z=（z1，…，zn）T。

利用上述公式和Y=μ+σ1/2Z的事实，我们可以通过雅可比公式计算Y1，…，Yn的节点密度这给了

![img](file:///C:/Users/ADMINI~1/AppData/Local/Temp/msohtmlclip1/01/clip_image004.gif)

式中y=（y1，…，yn）T。

# 2                多元正态随机变量的性质

假设Y=（Y1，…，Yn）T∼Nn（μ，σ）注意，μ是Y的平均向量E（Y），而∑是协方差矩阵Cov（Y）。以下特性非常重要。

\1.    Y的线性函数也是多元正态的：如果A是m×n确定性矩阵，c是m×1确定性向量，则Y+c∼Nm（Aμ+c，A∑AT）。

原因：a Y+c的每一个线性函数显然也是Y的一个线性函数，因此，这个事实遵循了多元正态分布的定义。

\2.    如果Y是多元正态的，那么取Y的一个子集所形成的每个随机向量也是多元正态的。

理由：从以前的事实来看。

\3.    独立性与不相关性相同：如果Y（1）和Y（2）是两个随机向量，那么Y=（Y（1）T，Y（2）T）T是多元正态的。当且仅当Cov（Y（1），Y（2））=0时，Y（1）和Y（2）是独立的。

原因：独立性意味着Cov（Y（1），Y（2））=0这一事实是显而易见的，不需要任何正态性。关键是另一个含义，即零协方差意味着独立性。因此，可以证明Y的MGF等于Y（1）和Y（2）的MGF的乘积Y的MGF

等于

![img](file:///C:/Users/ADMINI~1/AppData/Local/Temp/msohtmlclip1/01/clip_image006.gif)

其中∑=Cov（Y）。

注意Y（1）和Y（2）也是多元正态的，所以

当i=1,2时

哪里

μ（i）：=E（Y（i））和∑ii:=Cov（Y（i））。

如果∑12：=Cov（Y（1），Y（2））和∑，那么观察

![img](file:///C:/Users/ADMINI~1/AppData/Local/Temp/msohtmlclip1/01/clip_image008.gif)

因此，如果a=（a（1），a（2））T，则

.

在∑12=0的假设下，我们可以写出

![img](file:///C:/Users/ADMINI~1/AppData/Local/Temp/msohtmlclip1/01/clip_image010.gif)

从中可以看出

MY（a）=MY（1）（a（1））MY（2）（a（2））。

由于Y=（Y（1），Y（2））T的MGF分解为Y（1）的MGF和Y（2）的MGF的乘积，因此Y（1）和Y（2）是独立的。因此，在（Y（1），Y（2））T的多元正态性假设下，不相关等同于独立性。

\4.    假设Y=（Y1，…，Yn）T是多元正态随机向量那么两个分量Yi和Yj是独立的当且仅当∑ij=0其中∑Cov（Y）。

理由：直接从前面三个事实出发。

\5.    线性函数的独立性可以通过矩阵相乘来检验：假设Y是多元正态函数。那么当且仅当A∑BT=0时，AY和BY是独立的。原因：首先要注意

是多元正态的。因此，当且仅当Cov（AY，BY）=0时，AY和BY是独立的。然后，根据Cov（AY，BY）=A∑BT的观察结果，提出了该断言。

# 3                多元正态随机变量的性质

假设Y=（Y1，…，Yn）T∼Nn（μ，σ）注意，μ是Y的平均向量E（Y），而∑是协方差矩阵Cov（Y）。在上一节课中，我们研究了以下属性。

\1.    Y的线性函数也是多元正态的：如果A是m×n确定性矩阵，c是m×1确定性向量，则Y+c∼Nm（Aμ+c，A∑AT）。

\2.    由Y的一个子集构成的随机向量也是多元正态的。

\3.    独立性与不相关性相同：如果Y（1）和Y（2）是从Y获得的两个子向量，那么Y（1）和Y（2）是独立的，当且仅当Cov（Y（1），Y（2））=0。

\4.    两个分量Yi和Yj是独立的当且仅当∑ij=0其中∑Cov（Y）。

\5.    线性函数的独立性可以通过矩阵相乘来检验：当且仅当A∑BT=0时，y和by是独立的。

# 4                幂等矩阵与卡方分布

接下来，我们将证明具有恒等协方差的多元正态随机变量的二次型具有卡方分布，前提是定义二次型的对称矩阵是等幂的。如果A2=A，则称平方矩阵A为幂等矩阵。关于幂等矩阵的一个重要事实如下。

事实：如果A是秩r的n×n对称且幂等矩阵当且仅当

（82个）

对于r正交和单位长度向量u1，…，ur。

为了证明这个事实，首先要注意如果A是对称的，那么通过谱定理

![img](file:///C:/Users/ADMINI~1/AppData/Local/Temp/msohtmlclip1/01/clip_image012.gif)

对于正交基u1，…，un和实数λ1，…，λn，A的秩正好等于非零的λi的个数。如果r是A的秩，那么我们可以这样写（假设在不丧失一般性的情况下，λ1，…，λr是非零的，且λr+1=·····=λn=0）

.

接下来就是

.

因此，如果A是等幂的，那么A2=A

![img](file:///C:/Users/ADMINI~1/AppData/Local/Temp/msohtmlclip1/01/clip_image014.gif)

这意味着λ2i=λi，它给出了λi=1（注意，我们假设λi6=0）这证明了（82）。

下面的结果表明，如果下垫矩阵是等幂的，则具有恒等协方差的多元正态随机向量的二次型是卡方的。

定理54.1。假设Y∼n n（μ，In），设A是秩为r的n×n对称幂等矩阵，则

（Y-μ）TA（Y-μ）∼x2R。

证明因为A是对称的和幂等的，并且有秩r，我们可以把A写成

![img](file:///C:/Users/ADMINI~1/AppData/Local/Temp/msohtmlclip1/01/clip_image016.gif)

对于一些正交和单位范数向量u1，…，ur。那么

.

式中，Vi：=uTi（Y–）。现在请注意，每个Vi∼N（0,1）和V1，…，Vr是不相关的，因此是独立的（因为正态性）这证明了。

例54.2假设X1，…，Xn是i.i.d N（0,1）然后X∏∼N（0,1/N）和

.

此外，X′和S是独立的。

X∏N（0,1/N）很容易为了证明S∼x2n-1和S与X∼是独立的，我们将给出两种方法。

方法一：要证明S∼x2n-1，关键是要注意

![img](file:///C:/Users/ADMINI~1/AppData/Local/Temp/msohtmlclip1/01/clip_image018.gif)

其中X=（X1，…，Xn）T和1=（1，…，1）T。在上面的最后一步中，我们使用了对称的事实第一步，我们使用了

.

现在如果

,

那么很明显A是对称的和等幂的

![img](file:///C:/Users/ADMINI~1/AppData/Local/Temp/msohtmlclip1/01/clip_image020.gif)

A的秩也等于n-1因此通过定理54.1（注意X=（X1，…，Xn）T∼Nn（0，In）），我们得到

S=XTAX∼x2n-1。

为了证明S和X是独立的，我们只需要观察

和（83）

是独立的，因为S是

![img](file:///C:/Users/ADMINI~1/AppData/Local/Temp/msohtmlclip1/01/clip_image022.gif)

（83）中随机变量的独立性如下：

![img](file:///C:/Users/ADMINI~1/AppData/Local/Temp/msohtmlclip1/01/clip_image024.gif)

![img](file:///C:/Users/ADMINI~1/AppData/Local/Temp/msohtmlclip1/01/clip_image025.gif)

Rn，u1=1/√n（检查u1是否有单位方法二：设u1，…，un为范数的正交基）设U是列u1，…，un的矩阵，即。，

U=[u1:···：联合国]。

注意，UUT=UTU=In（根据正交基的性质）。现在让Y=UTX那么Y是X（和X∼Nn（0，In））的线性函数，因此

Y∼Nn（UT（0），utiu）=Nn（0，UTU）=Nn（0，In）。

进一步注意

北

X 2吨T T T X 2

Yi=Y Y=X UU X=X X=Xi（84）

i=1 i=1

还有那个因此，（84）给出

![img](file:///C:/Users/ADMINI~1/AppData/Local/Temp/msohtmlclip1/01/clip_image027.gif)

以便

![img](file:///C:/Users/ADMINI~1/AppData/Local/Temp/msohtmlclip1/01/clip_image029.gif)

这和Y∼N N（0，In）（也就是说Y1，…，Yn是i.i.dn（0，1））的事实意味着

. 还要注意，S仅依赖于√Y2，…，Yn，因此它独立于Y1，因此S和X

![img](file:///C:/Users/ADMINI~1/AppData/Local/Temp/msohtmlclip1/01/clip_image030.gif)

独立的（注意X‘=Y1/n）。

例54.3假设X∼n n（0，∑），其中∑是一个n×n矩阵，对角线上有1，非对角线上有ρσ也可以表示为

σ=（1−ρ）In+ρ11T，其中1：=（1，…，1）T。

也就是说，X1，…，Xn是多元正态的，具有均值零，单位方差，且每对之间的相关性等于ρ。找出X′的分布，并证明它们是独立的。

X是X的线性函数，所以它是正常的我们只需要找到它的均值和方差。显然，EX’=0（因为每个EXi=0）和

.

因此

.

观察到这意味着1+（n−1）ρ≥0或ρ≥-1/（n−1）换句话说，如果ρ<-1/（n-1），那么∑将不是半正定的。

为了找到S的分布，我们可以像前面的例子一样

![img](file:///C:/Users/ADMINI~1/AppData/Local/Temp/msohtmlclip1/01/clip_image032.gif)

但是我们不能不幸地使用定理54.1，因为X没有恒等协方差（定理54.1）仅适用于具有恒等协方差的多元正态随机向量。在这里，第二种方法（在前面的例子中描述）在这里工作并给出了S的分布，这在下面解释。

![img](file:///C:/Users/ADMINI~1/AppData/Local/Temp/msohtmlclip1/01/clip_image033.gif)

n其中u1=1/√n，设U为带列的矩阵，设u1，…，un为ru1，…，un的正交基，这样UTU=UUT=In设Y=UTX并注意（如前一个示例中所示）

![img](file:///C:/Users/ADMINI~1/AppData/Local/Temp/msohtmlclip1/01/clip_image034.gif)

Y1=√nX‘，S=Xn（X−X‘）2=Y22+····+Yn2。

我

i=1

Y的分布现在由Y∼Nn（0，UT∑U）和

.

要计算1TU，请注意

T T T√

1 U=（1 u1，1 u2，…，1 un）=（n，0，…，0）

√Tu1=1T1/√n=√n，事实上1与u2正交，…，un（这是因为

我们用的地方1

![img](file:///C:/Users/ADMINI~1/AppData/Local/Temp/msohtmlclip1/01/clip_image025.gif)

h1，uii=nhu1，i>1时uii=0）我们就这样得到了

UT∑U=（1−ρ）In+ρ（√n，0，…，0）T（√n，0，…，0）。

这意味着UT∑U是一个对角线矩阵，有对角线项（1--ρ+nρ），1--ρ，1--ρ，…，1--ρ因此Y∼Nn（0，UT∑U）表示Y1，…，Yn与

当i>1时，Y1∼N（0,1+（N-1）ρ）和Yi∼N（0,1-ρ）。

因此

![img](file:///C:/Users/ADMINI~1/AppData/Local/Temp/msohtmlclip1/01/clip_image036.gif)

或S∼（1-ρ）x2n-1另外，因为X′只依赖于Y1，S只依赖于Y2，…，Yn，我们认为S和X′是独立的。

# 5                多元正态分布的条件分布

假设Y∼Nn（μ，σ）让我们把Y分成两部分Y（1）和Y（2），其中Y（1）=（Y1，…，Y p）T由Y的前p个分量组成，Y（2）=（Yp+1，…，Y n）由Y的最后q:=n−p个分量组成。

然后我们可以类似地划分平均向量μ

![img](file:///C:/Users/ADMINI~1/AppData/Local/Temp/msohtmlclip1/01/clip_image038.gif)

协方差矩阵∑as

![img](file:///C:/Users/ADMINI~1/AppData/Local/Temp/msohtmlclip1/01/clip_image040.gif)

我们现在要解决的问题是：给定Y（1）=y1，Y（2）的条件分布是什么？答案如下。

事实：假设Y∼Nn（μ，σ），我们有

（85）

也就是说，给定Y（1）=y1的Y（2）的条件分布也是多元正态分布，平均向量由下式给出：

![img](file:///C:/Users/ADMINI~1/AppData/Local/Temp/msohtmlclip1/01/clip_image042.gif)

协方差矩阵由

.

我们将把下面（91）的证明翻一遍。在此之前，让我们就有条件分配的形式作几点简短的评论：

\1.    条件分布也是多元正态分布。

\2.    条件期望E（Y（2）| Y（1）=y1是y1的线性函数。

\3.    就Y（1）而言，E（Y（2）| Y（1））正好等于Y（2）的BLP因此BP和BLP是一致的。

\4.    条件协方差矩阵Cov（Y（2）| Y（1）=y1）不依赖于y1（这可视为某种同态性）。

\5.    条件协方差矩阵Cov（Y（2）| Y（1）=y1）等于∑S22（∑中∑22的Schur补）。换句话说，条件协方差矩阵Cov（Y（2）| Y（1）=y1精确地等于给定Y（1）的Y（2）的残差的协方差矩阵。

事实证明（91）：很容易看出（91）相当于：

.

进一步等同于

（86）

注意，上面右边的分布不依赖于y1因此（86）相当于

和

其中⊥⊥表示独立因为Y是多元正态函数，我们知道Y的线性函数也是多元正态函数，并且Y的线性函数是独立的，只要它们是不相关的。因此，上述断言相当于以下三个等式：

一

2。。

三。

换句话说，我们注意到证明上述三个方程等同于证明（91）。我们现在通过证明上述三个方程来完成（91）的证明。我们已经证明了这三个事实。第一个事实简单地说，给定Y（1）的Y（2）的余数具有零期望。第二个事实是残差的协方差矩阵等于Schur补。第三个事实是给定Y（1）的Y（2）的残差与Y（1）不相关。为了完整起见，让我们按如下所示快速地重新定义它们。

，（87）

（88个）

最后

=0（89）

这就完成了（91）的证明。

让我们重申，所有这三种计算（87），（88）和（89）不需要对Y（1）和Y（2）进行任何分配假设。它们适用于所有随机变量Y（1）和Y（2）多元正态性假设允许我们从这些二阶（即均值和协方差）计算中推断（91）。

# 6                多元正态分布与卡方分布的若干注记

在上节课上，我们看到了下面的结果。

定理56.1。如果Z∼Nn（0，In）和A是对称的幂等矩阵，则ZTAZ∼x2r，其中r是A的秩。

事实证明，这个结果的倒数也是真的，我们有

定理56.2。假设Z∼Nn（0，In）和A是对称矩阵。则ZTAZ∼x2r当且仅当A是秩r的幂等矩阵。

换句话说，ZTAZ具有卡方分布的唯一方法是当A是幂等的。因此，对于ZTAZ作为卡方分布来说，具有幂等性既是必要的，也是充分的。暗示A的幂等性的事实可以通过矩生成函数来证明，但我们将跳过这个论点。

当协方差不是恒等矩阵时，定理56.1需要修改如下所示。现在假设Y∼Nn（0，∑），我们有兴趣看看Q：=Y-TAY是幂等的

（这里A是对称矩阵）。我们知道Z：=是∑-1/2Y∼Nn（0，In），所以我们可以写（如Y=是∑1/2Z）

Q=Y TAY=ZT∑1/2A∑1/2Z。

因此Q是卡方分布的，当且仅当∑1/2A∑1/2是等幂的，它等价于

∑1/2A∑1/2∑1/2A∑1/2=1/2A∑1/2⇐⇐A∑A=A。

因此我们有

定理56.3假设Y∼Nn（0，∑）和A是对称矩阵。那么Y-TAY∼x2r当且仅当A∑A=A且r=秩（∑1/2A∑1/2）=秩（A）。

让我们看看这个结果的一些例子。

例56.4。假设Y∼n n（0，σ2In），设A为秩为r的n×n对称幂等矩阵，结果表明

.

这可以作为定理56.3的结果来证明，因为

![img](file:///C:/Users/ADMINI~1/AppData/Local/Temp/msohtmlclip1/01/clip_image044.gif)

和

.

例56.5。假设X∼n n（0，∑），其中∑是一个n×n矩阵，对角线上有1，非对角线上有ρ。σ也可以表示为

​                                                            Σ = (1 − *ρ*)*In* + *ρ***11***T                         where* **1** := (1*,...,*1)*T.*

*In the last class, we showed that*![img](file:///C:/Users/ADMINI~1/AppData/Local/Temp/msohtmlclip1/01/clip_image046.gif) *satisfies*

​                                                                                           ![img](file:///C:/Users/ADMINI~1/AppData/Local/Temp/msohtmlclip1/01/clip_image048.gif)*.*                                                                                   (90)

*We shall show this here using Theorem 56.3. Note first that*

![img](file:///C:/Users/ADMINI~1/AppData/Local/Temp/msohtmlclip1/01/clip_image050.gif)

*so that*

​                                                       ![img](file:///C:/Users/ADMINI~1/AppData/Local/Temp/msohtmlclip1/01/clip_image052.gif)        *where* ![img](file:///C:/Users/ADMINI~1/AppData/Local/Temp/msohtmlclip1/01/clip_image054.gif)

*Thus to show* (90)*, we only need to prove that A*Σ*A* = *A. For this, see that*

![img](file:///C:/Users/ADMINI~1/AppData/Local/Temp/msohtmlclip1/01/clip_image056.gif)

*so that A*Σ*A* = *A. Thus Theorem 56.3 immediately gives* (90)*.*

**Example 56.6.** *Suppose Y* ∼ *Nn*(0*,*Σ)*. Then*![img](file:///C:/Users/ADMINI~1/AppData/Local/Temp/msohtmlclip1/01/clip_image058.gif)*. This follows directly from Theorem 56.3 by taking A* = Σ−1*.*

Finally let us mention that when *Z* ∼ *Nn*(*µ,In*) and *A* is idempotent, then *ZTAZ* will be a non-central chi-squared distribution. We will not study these in this class.

# 7                Conditional Distributions of Multivariate Normals

Suppose that *Y*(1) and *Y*(2) are two random vectors (with possibly different lengths) such that the vector ![img](file:///C:/Users/ADMINI~1/AppData/Local/Temp/msohtmlclip1/01/clip_image060.gif) is multivariate normal. Then, as we saw in the last class, we have

![img](file:///C:/Users/ADMINI~1/AppData/Local/Temp/msohtmlclip1/01/clip_image062.gif)                                                                                                                                                                          ))                            (91)

(92)

In words, the conditional distribution of *Y*(2) given *Y*(1) = *y*1 is also multivariate normal with mean vector given by:

![img](file:///C:/Users/ADMINI~1/AppData/Local/Temp/msohtmlclip1/01/clip_image064.gif)

and covariance matrix given by

*Cov*(*Y*(2)|*Y*(1) = *y*1) = *Cov*(*Y*(2)) − *Cov*(*Y*(2)*,Y*(1))(*CovY*(1))−1*Cov*(*Y*(1)*,Y*(2))

It is important to note that

\1.    E(*Y*(2)|*Y*(1)) is exactly equal to the BLP of *Y*(2) in terms of *Y*(1). Thus the BP and BLP coincide.

\2.    The conditional covariance matrix *Cov*(*Y*(2)|*Y*(1) = *y*1) does not depend on *y*1 (this can be viewed as some kind of *homoscedasticity*).

\3.    The conditional covariance matrix *Cov*(*Y*(2)|*Y*(1) = *y*1) is precisely equal to the Covariance Matrix of the Residual of *Y*(2) given *Y*(1).

​            We can look at the following special case of this result.              Fix two components *Yi* and *Yj* of *Y* .          Let

*Y*(2) := (*Yi,Yj*)*T* and let *Y*(1) denote the vector obtained from all the other components *Yk,k* 6= *i,k* 6= *j*. Then

*Cov*(*Y*(2)|*Y*(1) = *y*1) = *Cov*(*Y*(2)) − *Cov*(*Y*(2)*,Y*(1))(*CovY*(1))−1*Cov*(*Y*(1)*,Y*(2))

Now let *rY**i*|*Y**k**,k*6=*i,k*6=*j* and *rY**j*|*Y**k**,k*6=*i,k*6=*j* denote the residuals of *Yi* in terms of *Yk,k* 6= *i,k* 6= *j* and *Yj* in terms of *Yk,k* 6= *i,k* 6= *j*, then we have seen previously that

![img](file:///C:/Users/ADMINI~1/AppData/Local/Temp/msohtmlclip1/01/clip_image066.gif)*.*

We thus have

​                     ![img](file:///C:/Users/ADMINI~1/AppData/Local/Temp/msohtmlclip1/01/clip_image068.gif)            for every *yk,k* 6= *i,k* 6= *j.*

This means, in particular, that the conditional correlation between *Yi* and *Yj* given *Yk* = *yk,k* 6= *i,k* 6= *j*

is precisely equal to the partial correlation *ρY**i,Y**j*|*Y**k**,k*6=*i,k*6=*j* (recall that *ρY**i,Y**j*|*Y**k**,k*6=*i,k*6=*j* is the correlation between *r**Yi*|*Yk,k*6=*i,k*6=*j* and *r**Yj*|*Yk,k*6=*i,k*6=*j*).

Now recall the following connection between partial correlation and entries of Σ−1 that we have seen earlier:

![img](file:///C:/Users/ADMINI~1/AppData/Local/Temp/msohtmlclip1/01/clip_image070.gif)*.*

Putting the above observations together, we can deduce that the following are **equivalent** when *Y* is multivariate normal with covariance matrix Σ:

\1.    Σ−1(*i,j*) = 0

\2.    *ρ**Yi,Yj*|*Yk,k*6=*i,k*6=*j* = 0

\3.    The conditional correlation between *Yi* and *Yj* given *Yk* = *yk,k* 6= *i,k* =6 *j* equals 0 for every choice of *yk,k* 6= *i,k* 6= *j*.

\4.    *Yi* and *Yj* are conditionally independent given *Yk* = *yk,k* 6= *i,k* 6= *j* equals 0 for every choice of *yk,k* 6= *i,k* 6= *j*.